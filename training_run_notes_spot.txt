





Tab 7: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_19990_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt
Tab 8: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_19998_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt

Tab 9: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_19999_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt
Tab 10: ~/src/CoppeliaSim_Edu_V4_0_0_Ubuntu18_04/coppeliaSim.sh -gREMOTEAPISERVERSERVICE_20000_FALSE_TRUE -s ~/src/real_good_robot/simulation/simulation.ttt





SIM STACK - SPOT STANDARD Trial rtrial Task Progress - TRIAL REWARD - RANDOM ACTIONS - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
RESUME: ± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-09-32_Sim-Stack-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-09-32_Sim-Stack-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7

CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions


SIM ROW - SPOT STANDARD Trial rtrial Task Progress - TRIAL REWARD - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
RESUME: export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions - Resumed june 2020
RESUME: GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10
RESUME Commit: 36a0c6a8cfd6c0d8a087f0b647814575054faedd release tag: v0.16.3
RESUME: export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training

    > '/home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training/2020-06-11-00-40-54_Sim-Rows-SPOT-Trial-Reward-Testing/best_stats.json'
    > {"action_efficiency_best_index": 1779, "action_efficiency_best_value": 0.29375351716375914, "grasp_success_rate_best_index": 1778, "grasp_success_rate_best_value": 0.33109619686800895, "place_success_rate_best_index": null, "place_success_rate_best_value": -Infinity, "trial_success_rate_best_index": 1777, "trial_success_rate_best_value": 0.74}
    >
    > place success rate log value: 8.744292237442922167e-01 
    > Manually edited json with place success rate :
    > '/home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training/2020-06-11-00-40-54_Sim-Rows-SPOT-Trial-Reward-Testing/best_stats.json'
    > {"action_efficiency_best_index": 1779, "action_efficiency_best_value": 0.29375351716375914, "grasp_success_rate_best_index": 1778, "grasp_success_rate_best_value": 0.33109619686800895, "place_success_rate_best_index": null, "place_success_rate_best_value": 0.874, "trial_success_rate_best_index": 1777, "trial_success_rate_best_value": 0.74}




SIM STACK - Trial Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
RESUME: export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-00_Sim-Stack-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-00_Sim-Stack-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 2, Tab 2, port 19999, left v-rep window, v-rep tab 9


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions


SIM ROW - Trial Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-28
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
RESUME: ± export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward --resume /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-38_Sim-Rows-SPOT-Trial-Reward-Training
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-28-12-11-38_Sim-Rows-SPOT-Trial-Reward-Training
Commit: a534735959ec2747c3b134a6d3067135a5c7bd75  release tag:v0.16.0
GPU 3, Tab 3, port 19999, center left v-rep window, v-rep tab 10


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 7k actions











SIM ROW - Trial Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-12-47_Sim-Rows-SPOT-Trial-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 3, Tab 3, port 19999, center left v-rep window, v-rep tab 10


CANCELLED BECAUSE IT IS NOT THE RUN WE NEED RIGHT NOW - 2020-05-30 - TODO MAYBE RESUME LATER, finished around 1k actions





Pass 1 - Ablation of instant reward shcedules
============================================================================================================================











SIM STACK - Task Progress aka progress only - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-09-38_Sim-Stack-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7



    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 3.220978 (push), 7.850247 (grasp), 7.190622 (place)
    > Action: grasp at (4, 7, 152)
    > Training loss: 0.672980
    > Executing: grasp at (-0.420000, -0.210000, 0.001003) orientation: 1.570796
    > gripper position: 0.0304451584815979
    > gripper position: 0.026506200432777405
    > gripper position: 0.0013817846775054932
    > gripper position: -0.022582605481147766
    > gripper position: -0.04284219443798065
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05112840983826451 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0225681967652902 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0225681967652902 stack matches current goal: False partial_stack_success: False Does the code think a reset
    > is needed: False
    > STACK:  trial: 101 actions/partial: 3.662721893491124  actions/full stack: 12.505050505050505 (lower is better)  Grasp Count: 663, grasp success rate: 0.8310708898944194 place_on_stack_rate: 0.6134301270417423 place_attempts: 551  partial_stack_successes: 338  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: None current_height: 1.0225681967652902
    > trial_complete_indices: [  13.   19.   32.   44.   68.   76.   86.  102.  112.  118.  125.  133.
    >   139.  145.  180.  186.  192.  198.  205.  213.  221.  232.  240.  293.
    >   299.  309.  317.  323.  333.  349.  354.  365.  376.  380.  393.  403.
    >   420.  456.  476.  492.  496.  504.  515.  521.  531.  537.  543.  551.
    >   560.  575.  585.  591.  600.  610.  620.  631.  639.  645.  652.  658.
    >   672.  704.  711.  717.  721.  729.  746.  758.  764.  770.  778.  784.
    >   790.  796.  806.  812.  855.  861.  897.  905.  915.  919.  928.  962.
    >   968.  972.  979.  987.  993.  997. 1007. 1013. 1031. 1043. 1149. 1160.
    >  1168. 1178. 1195. 1231. 1237.]
    > Max trial success rate: 0.98, at action iteration: 1234. (total of 1236 actions, max excludes first 1234 actions)
    > Max grasp success rate: 0.8335854765506808, at action iteration: 1235. (total of 1236 actions, max excludes first 1234 actions)
    > Max place success rate: 0.7426086956521739, at action iteration: 1236. (total of 1237 actions, max excludes first 1234 actions)
    > Max action efficiency: 0.5153970826580226, at action iteration: 1236. (total of 1237 actions, max excludes first 1234 actions)
    > saving plot: 2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing-Sim-Stack-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-09-38_Sim-Stack-Two-Step-Reward-Training/2020-06-03-03-08-00_Sim-Stack-Two-Step-Reward-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 1234, 'grasp_success_rate_best_value': 0.8335854765506808, 'grasp_success_rate_best_index': 1235, 'place_success_rate_best_value': 0.7426086956521739, 'place_success_rate_best_index': 1236, 'action_efficiency_best_value': 0.5153970826580226, 'action_efficiency_best_index': 1236}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-09-38_Sim-Stack-Two-Step-Reward-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8103448275862069, 'trial_success_rate_best_index': 19569, 'grasp_success_rate_best_value': 0.9494163424124513, 'grasp_success_rate_best_index': 12019, 'place_success_rate_best_value': 0.8312236286919831, 'place_success_rate_best_index': 17156, 'action_efficiency_best_value': 0.6, 'action_efficiency_best_index': 19471}



SIM ROW - Task Progress aka progress only - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-10-52_Sim-Rows-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8



    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 5.558454 (push), 8.079895 (grasp), 9.956761 (place)
    > Action: grasp at (4, 183, 167)
    > Training loss: 0.173360
    > Executing: grasp at (-0.390000, 0.142000, 0.001004) orientation: 1.570796
    > gripper position: 0.030987784266471863
    > gripper position: 0.02650594152510166
    > gripper position: 0.0014807581901550293
    > gripper position: -0.023117437958717346
    > gripper position: -0.042321473360061646
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05110803083189876 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 2 | blocks: ['blue' 'red']
    > check_stack() stack_height: 2 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 6.386363636363637  actions/full stack: 11.46938775510204 (lower is better)  Grasp Count: 618, grasp success rate: 0.8220064724919094 place_on_stack_rate: 0.34782608695652173 place_attempts: 506  partial_stack_successes: 176  stack_successes: 98 trial_success_rate: 0.9702970297029703 stack goal: [3 2] current_height: 2
    > trial_complete_indices: [   4.    8.   12.   18.   23.   28.   32.   36.   40.   44.   50.   54.
    > 58.   62.   66.   68.   72.   76.   80.   84.  485.  491.  499.  503.
    > 509.  511.  517.  521.  525.  708.  712.  714.  720.  728.  730.  736.
    > 740.  742.  749.  753.  758.  770.  776.  778.  786.  790.  794.  801.
    > 805.  809.  811.  813.  815.  819.  828.  832.  836.  840.  845.  849.
    > 861.  865.  869.  872.  878.  882.  886.  888.  890.  894.  896.  900.
    > 904.  950.  955.  957.  963.  968.  976.  980.  982.  988.  991.  993.
    > 999. 1044. 1053. 1057. 1064. 1068. 1074. 1078. 1092. 1096. 1100. 1104.
    > 1106. 1110. 1114. 1118. 1123.]
    > Max trial success rate: 0.97, at action iteration: 1120. (total of 1122 actions, max excludes first 1120 actions)
    > Max grasp success rate: 0.823051948051948, at action iteration: 1120. (total of 1122 actions, max excludes first 1120 actions)
    > Max place success rate: 0.8950495049504951, at action iteration: 1120. (total of 1123 actions, max excludes first 1120 actions)
    > Max action efficiency: 0.5303571428571429, at action iteration: 1122. (total of 1123 actions, max excludes first 1120 actions)
    > saving plot: 2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-10-52_Sim-Rows-Two-Step-Reward-Training/2020-06-03-07-00-00_Sim-Rows-Two-Step-Reward-Testing
    > Random Testing results:
    > {'trial_success_rate_best_value': 0.97, 'trial_success_rate_best_index': 1120, 'grasp_success_rate_best_value': 0.823051948051948, 'grasp_success_rate_best_index': 1120, 'place_success_rate_best_value': 0.8950495049504951, 'place_success_rate_best_index': 1120, 'action_efficiency_best_value': 0.5303571428571429, 'action_efficiency_best_index': 1122}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-10-52_Sim-Rows-Two-Step-Reward-Training
    > Training results:
    > {'action_efficiency_best_index': 18908, 'action_efficiency_best_value': 1.248, 'grasp_success_rate_best_index': 17217, 'grasp_success_rate_best_value': 0.8145454545454546, 'place_success_rate_best_index': 13436, 'place_success_rate_best_value': 0.9345794392523364, 'trial_success_rate_best_index': 18572, 'trial_success_rate_best_value': 0.768}





SIM STACK - Basic Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-13-11-57_Sim-Stack-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 2, Tab 2, port 19999, left v-rep window, v-rep tab 9

    > '/home/ahundt/src/real_good_robot/logs/2020-05-30-13-11-57_Sim-Stack-Two-Step-Reward-Training/2020-06-02-19-24-53_Sim-Stack-Two-Step-Reward-Testing'
    > {"action_efficiency_best_index": 7161, "action_efficiency_best_value": 0.07710574102528286, "grasp_success_rate_best_index": 7159, "grasp_success_rate_best_value": 0.8780807551127425, "place_success_rate_best_index": 7159, "place_success_rate_best_value": 0.6434548714883442, "trial_success_rate_best_index": 7159, "trial_success_rate_best_value": 0.9}


SIM ROW - Basic Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-05-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-05-30-17-46-01_Sim-Rows-Two-Step-Reward-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 3, Tab 3, port 20000, center left v-rep window, v-rep tab 10


    > Complete first test run trial success rate best value model:
    > {"action_efficiency_best_index": 2092, "action_efficiency_best_value": 0.28995215311004785, "grasp_success_rate_best_index": 2090, "grasp_success_rate_best_value": 0.8680926916221033, "place_success_rate_best_index": 2090, "place_success_rate_best_value": 0.5927835051546392, "trial_success_rate_best_index": 2090, "trial_success_rate_best_value": 0.94}
    > Max trial success rate: 0.94, at action iteration: 2090. (total of 2092 actions, max excludes first 2090 actions)                         
    > Max grasp success rate: 0.8680926916221033, at action iteration: 2090. (total of 2092 actions, max excludes first 2090 actions)           Max place success rate: 0.5927835051546392, at action iteration: 2090. (total of 2091 actions, max excludes first 2090 actions)           
    > Max action efficiency: 0.28995215311004785, at action iteration: 2092. (total of 2093 actions, max excludes first 2090 actions)           
    > saving plot: 2020-06-03-06-28-31_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png                       saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-06-28-31_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json     
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-06-28-31_Sim-Rows-Two-Step-Reward-Testing/best_stats.json          
    > Trial logging complete: 101 --------------------------------------------------------------



    > *Partially* complete second test run, best action efficiency model:
    > -------------------------------------
    > Max trial success rate: 0.9710144927536232, at action iteration: 1741. (total of 1743 actions, max excludes first 1741 actions)
    > Max grasp success rate: 0.9186176142697882, at action iteration: 1741. (total of 1743 actions, max excludes first 1741 actions)           
    > Max place success rate: 0.6415552855407047, at action iteration: 1741. (total of 1742 actions, max excludes first 1741 actions)
    > Max action efficiency: 0.24813325674899483, at action iteration: 1743. (total of 1744 actions, max excludes first 1741 actions)
    > saving plot: 2020-06-03-15-46-00_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png                       
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-15-46-00_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json     saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-03-15-46-00_Sim-Rows-Two-Step-Reward-Testing/best_stats.json          
    > Trial logging complete: 70 -------------------------------------------------------------- 











Pass 2 - SPOT-Q TASK PROGRESS MASKED
===========================================================================================================================







SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-03-11-44-02_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7

    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05115434739934034 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0230869479868068 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0230869479868068 stack matches current goal: False partial_stack_success: False Does the code think a reset
    > is needed: False
    > STACK:  trial: 101 actions/partial: 3.8494318181818183  actions/full stack: 13.415841584158416 (lower is better)  Grasp Count: 768, grasp
    > success rate: 0.7552083333333334 place_on_stack_rate: 0.6068965517241379 place_attempts: 580  partial_stack_successes: 352  stack_successes: 101 trial_success_rate: 1.0 stack goal: None current_height: 1.0230869479868068
    > trial_complete_indices: [   7.   20.   30.   36.   45.   74.   84.   99.  118.  138.  167.  177.
    >   189.  213.  225.  249.  255.  269.  275.  283.  290.  305.  323.  327.
    >   341.  351.  360.  391.  403.  420.  446.  457.  472.  481.  505.  534.
    >   543.  553.  562.  573.  592.  600.  606.  620.  626.  658.  664.  674.
    >   680.  689.  697.  705.  709.  726.  737.  745.  760.  764.  770.  780.
    >   791.  827.  850.  862.  878.  897.  905.  917.  930.  958.  971.  982.
    >  1022. 1028. 1034. 1047. 1062. 1069. 1078. 1084. 1102. 1109. 1114. 1133.
    >  1145. 1165. 1173. 1184. 1221. 1233. 1241. 1252. 1275. 1282. 1290. 1296.
    >  1312. 1319. 1333. 1342. 1354.]
    > Max trial success rate: 1.0, at action iteration: 1351. (total of 1353 actions, max excludes first 1351 actions)
    > Max grasp success rate: 0.7558746736292428, at action iteration: 1351. (total of 1353 actions, max excludes first 1351 actions)
    > Max place success rate: 0.757679180887372, at action iteration: 1351. (total of 1354 actions, max excludes first 1351 actions)
    > Max action efficiency: 0.44855662472242785, at action iteration: 1353. (total of 1354 actions, max excludes first 1351 actions)
    > saving plot: 2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-11-44-02_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-07-06-26-25_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1351, 'grasp_success_rate_best_value': 0.7558746736292428, 'grasp_success_rate_best_index': 1351, 'place_success_rate_best_value': 0.757679180887372, 'place_success_rate_best_index': 1351, 'action_efficiency_best_value': 0.44855662472242785, 'action_efficiency_best_index': 1353}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-11-44-02_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7931034482758621, 'trial_success_rate_best_index': 12797, 'grasp_success_rate_best_value': 0.937984496124031, 'grasp_success_rate_best_index': 13126, 'place_success_rate_best_value': 0.8201754385964912, 'place_success_rate_best_index': 19959, 'action_efficiency_best_value': 0.576, 'action_efficiency_best_index': 12886}




SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-03-12-05-28_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8


    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05113576211473993 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 2 | blocks: ['blue' 'green']
    > check_stack() stack_height: 2 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: True
    > main.py check_stack() DETECTED PROGRESS REVERSAL, mismatch between the goal height: 3 and current workspace stack height: 2
    > STACK:  trial: 101 actions/partial: 3.1473214285714284  actions/full stack: 7.05 (lower is better)  Grasp Count: 372, grasp success rate:
    > 0.8978494623655914 place_on_stack_rate: 0.6726726726726727 place_attempts: 333  partial_stack_successes: 224  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: [3 2 0 1] current_height: 2
    > trial_complete_indices: [  2.   8.  12.  23.  27.  31.  35.  39.  50.  58.  60.  66.  75.  86.
    >   88.  94. 103. 109. 112. 116. 122. 130. 136. 140. 146. 152. 172. 176.
    >  183. 189. 193. 200. 203. 212. 219. 223. 227. 233. 239. 251. 260. 269.
    >  273. 279. 287. 293. 297. 307. 313. 319. 328. 332. 338. 342. 346. 350.
    >  352. 354. 358. 360. 362. 367. 375. 381. 408. 412. 415. 419. 423. 435.
    >  441. 445. 449. 451. 453. 457. 461. 467. 475. 482. 491. 495. 503. 511.
    >  515. 522. 524. 535. 541. 545. 551. 557. 561. 563. 567. 576. 580. 686.
    >  693. 699. 704.]
    > Max trial success rate: 0.99, at action iteration: 701. (total of 703 actions, max excludes first 701 actions)
    > Max grasp success rate: 0.9, at action iteration: 701. (total of 703 actions, max excludes first 701 actions)
    > Max place success rate: 0.7921686746987951, at action iteration: 701. (total of 704 actions, max excludes first 701 actions)
    > Max action efficiency: 0.8473609129814551, at action iteration: 701. (total of 704 actions, max excludes first 701 actions)
    > saving plot: 2020-06-07-00-35-36_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-00-35-36_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-00-35-36_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-12-05-28_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-06-21-34-07_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 667, 'grasp_success_rate_best_value': 0.850415512465374, 'grasp_success_rate_best_index': 667, 'place_success_rate_best_value': 0.7752442996742671, 'place_success_rate_best_index': 667, 'action_efficiency_best_value': 0.9265367316341829, 'action_efficiency_best_index': 667}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-12-05-28_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7475728155339806, 'trial_success_rate_best_index': 18139, 'grasp_success_rate_best_value': 0.8550185873605948, 'grasp_success_rate_best_index': 18207, 'place_success_rate_best_value': 0.8486238532110092, 'place_success_rate_best_index': 19937, 'action_efficiency_best_value': 1.224, 'action_efficiency_best_index': 19986}






SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 2, Tab 2, port 19999, right center v-rep window, v-rep tab 9

    > note that we ran one extra test with place success rate, since it appears there was a glitch in the action efficiency records. This is a simulator bug which may worsen final results.
    > '/home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-07-19-54-35_Sim-Stack-Two-Step-Reward-Masked-Testing'
    > {"action_efficiency_best_index": 2284, "action_efficiency_best_value": 0.25241016652059595, "grasp_success_rate_best_index": 2282, "grasp_success_rate_best_value": 0.7245283018867924, "place_success_rate_best_index": 2282, "place_success_rate_best_value": 0.6659707724425887, "trial_success_rate_best_index": 2282, "trial_success_rate_best_value": 0.94}
    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 3.534616 (push), 7.419805 (grasp), 7.226346 (place)
    > Action: grasp at (0, 168, 167)
    > Training loss: 0.130998
    > Executing: grasp at (-0.390000, 0.112000, 0.051003) orientation: 0.000000
    > gripper position: 0.03104463219642639
    > gripper position: 0.026297718286514282
    > gripper position: 0.0010769963264465332
    > gripper position: -0.022954285144805908
    > gripper position: -0.04172489047050476
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05112415348966427 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0224830697932854 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0224830697932854 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 5.6658536585365855  actions/full stack: 23.948453608247423 (lower is better)  Grasp Count: 1344, grasp success rate: 0.7313988095238095 place_on_stack_rate: 0.4187946884576098 place_attempts: 979  partial_stack_successes: 410  stack_successes: 97 trial_success_rate: 0.9603960396039604 stack goal: None current_height: 1.0224830697932854
    > trial_complete_indices: [   9.   17.   37.   64.   79.   90.  159.  220.  224.  232.  260.  271.
    > 279.  290.  304.  314.  393.  425.  479.  483.  502.  508.  518.  533.
    > 551.  582.  598.  604.  617.  632.  636.  648.  660.  692.  700.  719.
    > 743.  767.  794.  809.  840.  850.  996. 1008. 1016. 1045. 1071. 1087.
    > 1105. 1116. 1141. 1160. 1207. 1287. 1306. 1321. 1330. 1339. 1359. 1403.
    > 1417. 1431. 1438. 1449. 1459. 1519. 1544. 1550. 1593. 1605. 1611. 1647.
    > 1664. 1683. 1692. 1706. 1720. 1767. 1797. 1934. 1958. 2008. 2031. 2048.
    > 2070. 2079. 2099. 2111. 2121. 2131. 2137. 2146. 2163. 2203. 2219. 2229.
    > 2241. 2246. 2254. 2305. 2322.]
    > Max trial success rate: 0.96, at action iteration: 2319. (total of 2321 actions, max excludes first 2319 actions)
    > Max grasp success rate: 0.732488822652757, at action iteration: 2320. (total of 2321 actions, max excludes first 2319 actions)
    > Max place success rate: 0.693564862104188, at action iteration: 2321. (total of 2322 actions, max excludes first 2319 actions)
    > Max action efficiency: 0.25097024579560157, at action iteration: 2321. (total of 2322 actions, max excludes first 2319 actions)
    > saving plot: 2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-08-05-43-46_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    > {'trial_success_rate_best_value': 0.96, 'trial_success_rate_best_index': 2319, 'grasp_success_rate_best_value': 0.732488822652757, 'grasp_success_rate_best_index': 2320, 'place_success_rate_best_value': 0.693564862104188, 'place_success_rate_best_index': 2321, 'action_efficiency_best_value': 0.25097024579560157, 'action_efficiency_best_index': 2321}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-04-11-18-49_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    > {'trial_success_rate_best_value': 0.8125, 'trial_success_rate_best_index': 10322, 'grasp_success_rate_best_value': 0.8905660377358491, 'grasp_success_rate_best_index': 10252, 'place_success_rate_best_value': 0.8028169014084507, 'place_success_rate_best_index': 4893, 'action_efficiency_best_value': 0.792, 'action_efficiency_best_index': 12478}



SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-03-23-18-31_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: 12d9481717486342dbfcaff191ddb1428f102406  release tag:v0.16.1
GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10


    > Trial logging complete: 101 --------------------------------------------------------------
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.051105467279345854 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 3 | blocks: ['blue' 'green' 'red']
    > check_stack() stack_height: 3 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 2.911214953271028  actions/full stack: 6.23 (lower is better)  Grasp Count: 333, grasp success rate: 0.8738738738738738 place_on_stack_rate: 0.7379310344827587 place_attempts: 290  partial_stack_successes: 214  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: [0 2] current_height: 3
    > trial_complete_indices: [  4.   8.  10.  12.  17.  40.  54.  61.  65.  71.  78.  82.  87.  91.
    >   95.  99. 101. 105. 111. 117. 123. 127. 131. 135. 143. 147. 151. 155.
    >  159. 169. 173. 177. 181. 190. 196. 200. 206. 210. 214. 220. 225. 232.
    >  240. 244. 252. 256. 260. 268. 272. 299. 303. 315. 325. 330. 334. 336.
    >  343. 349. 351. 356. 364. 368. 370. 374. 378. 403. 414. 418. 420. 428.
    >  432. 436. 440. 442. 446. 450. 458. 464. 479. 490. 535. 538. 542. 546.
    >  554. 556. 562. 568. 577. 579. 581. 585. 589. 591. 595. 599. 605. 609.
    >  616. 618. 622.]
    > Max trial success rate: 0.98, at action iteration: 619. (total of 621 actions, max excludes first 619 actions)
    > Max grasp success rate: 0.8761329305135952, at action iteration: 619. (total of 621 actions, max excludes first 619 actions)
    > Max place success rate: 0.7612456747404844, at action iteration: 621. (total of 622 actions, max excludes first 619 actions)
    > Max action efficiency: 0.9693053311793215, at action iteration: 621. (total of 622 actions, max excludes first 619 actions)
    > saving plot: 2020-06-07-20-09-08_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-20-09-08_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-07-20-09-08_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-23-18-31_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-07-17-17-16_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 614, 'grasp_success_rate_best_value': 0.9190031152647975, 'grasp_success_rate_best_index': 614, 'place_success_rate_best_value': 0.7627118644067796, 'place_success_rate_best_index': 615, 'action_efficiency_best_value': 1.01628664495114, 'action_efficiency_best_index': 616}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-03-23-18-31_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8034188034188035, 'trial_success_rate_best_index': 19062, 'grasp_success_rate_best_value': 0.8321167883211679, 'grasp_success_rate_best_index': 17961, 'place_success_rate_best_value': 0.9090909090909091, 'place_success_rate_best_index': 19959, 'action_efficiency_best_value': 1.26, 'action_efficiency_best_index': 19903}















Pass 3
============================================================



SIM ROW - Basic Situation Removal - RANDOM ACTIONS - SORT TRIAL REWARD -  REWARD SCHEDULE 0.1, 1, 1 - costar 2020-06-07
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --no_height_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-06-58_Sim-Rows-Two-Step-Reward-Training
Commit: 84d192f5e33a8da14b5da245f6649bed9f816884  release tag:v0.16.2
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7

    > Trial logging complete: 101 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 2.128928 (push), 2.290924 (grasp), 2.470773 (place)
    > Action: grasp at (12, 56, 135)
    > Training loss: 0.090713
    > Executing: grasp at (-0.454000, -0.112000, 0.001002) orientation: 4.712389
    > gripper position: 0.030810609459877014
    > gripper position: 0.026403671130537987
    > gripper position: 0.0011664032936096191
    > gripper position: -0.022915594279766083
    > gripper position: -0.04185757040977478
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.05111169094181285 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row() object_color_sequence length is 0 or 1, so there is nothing to check and it passes automatically
    > check_stack() stack_height: 1 stack matches current goal: True partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 7.6036363636363635  actions/full stack: 22.010526315789473 (lower is better)  Grasp Count: 1120, grasp success rate: 0.8464285714285714 place_on_stack_rate: 0.291005291005291 place_attempts: 945  partial_stack_successes: 275  stack_successes: 95 trial_success_rate: 0.9405940594059405 stack goal: [0] current_height: 1
    > trial_complete_indices: [   6.    8.   45.   67.  303.  311.  315.  323.  348.  375.  381.  418.
    >   428.  501.  503.  516.  525.  578.  584.  603.  615.  673.  697.  704.
    >   710.  716.  734.  749.  755.  772.  807.  813.  825.  835.  843.  847.
    >   856.  863.  867.  884.  979.  985.  996. 1002. 1008. 1014. 1033. 1037.
    >  1059. 1067. 1071. 1083. 1085. 1095. 1099. 1114. 1131. 1139. 1147. 1151.
    >  1157. 1163. 1175. 1193. 1199. 1214. 1258. 1264. 1289. 1302. 1310. 1312.
    >  1335. 1339. 1387. 1412. 1420. 1478. 1484. 1530. 1538. 1542. 1564. 1588.
    >  1625. 1642. 1650. 1654. 1656. 1704. 1741. 1828. 1841. 1872. 1896. 1954.
    >  2000. 2057. 2063. 2086. 2090.]
    > Max trial success rate: 0.93, at action iteration: 2087. (total of 2089 actions, max excludes first 2087 actions)
    > Max grasp success rate: 0.8470483005366727, at action iteration: 2087. (total of 2089 actions, max excludes first 2087 actions)
    > Max place success rate: 0.6610169491525424, at action iteration: 2087. (total of 2090 actions, max excludes first 2087 actions)
    > Max action efficiency: 0.2788691902252036, at action iteration: 2089. (total of 2090 actions, max excludes first 2087 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing-Sim-Rows-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-05-20-24_Sim-Rows-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-06-58_Sim-Rows-Two-Step-Reward-Training/2020-06-10-23-16-04_Sim-Rows-Two-Step-Reward-Testing
    > Random Testing results: 
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 1456, 'grasp_success_rate_best_value': 0.8350125944584383, 'grasp_success_rate_best_index': 1457, 'place_success_rate_best_value': -inf, 'place_success_rate_best_index': None, 'action_efficiency_best_value': 0.4368131868131868, 'action_efficiency_best_index': 1458}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-06-58_Sim-Rows-Two-Step-Reward-Training
    > Training results: 
    >  {'trial_success_rate_best_value': 0.5211267605633803, 'trial_success_rate_best_index': 10892, 'grasp_success_rate_best_value': 0.7992831541218638, 'grasp_success_rate_best_index': 16239, 'place_success_rate_best_value': 0.6807511737089202, 'place_success_rate_best_index': 19740, 'action_efficiency_best_value': 0.6, 'action_efficiency_best_index': 19564}


    TODO(ahundt) figure out the source of the place success rate infinite test bug. I looked it up manually in the log and the final value is 6.042296072507552518e-01 (60\%)


Parameter sensitivity experiment - SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 1, 1, 1 - workstation named spot 2020-06-07
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: 169ee86203c2a360b14fac69bd4b5cef86de3e83  release tag:push_r_weight_1.0_v0
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8

    > Something really unusual happened here, as trial success wasn't recoreded correctly. Remember this is not a typical run, REWARD SCHEDULE 1, 1, 1 is changed significantly, (push 0.1 -> 1.0). 
    > trial_complete_indices: [  10.   21.   26.   31.   36.   51.   62.   75.   83.   93.  112.  125.
    >   140.  146.  160.  168.  179.  193.  207.  212.  222.  228.  232.  244.
    >   254.  264.  274.  284.  285.  300.  309.  320.  336.  347.  350.  363.
    >   372.  382.  394.  402.  407.  419.  421.  433.  443.  451.  459.  471.
    >   484.  495.  506.  509.  520.  529.  535.  548.  558.  567.  576.  588.
    >   591.  605.  616.  633.  645.  655.  669.  680.  703.  721.  747.  753.
    >   768.  780.  792.  794.  805.  815.  823.  830.  839.  853.  869.  881.
    >   891.  903.  913.  931.  946.  947.  955.  965.  973.  978.  985.  995.
    >  1007. 1028. 1039. 1053.]
    > /home/ahundt/src/real_good_robot/plot.py:136: RuntimeWarning: invalid value encountered in double_scalars
    >   var = np.sqrt(success_rate[i] * (1 - success_rate[i]) / successes.shape[0])
    > Max grasp success rate: 1.0, at action iteration: 1056. (total of 1058 actions, max excludes first 1056 actions)
    > Max place success rate: 0.6666666666666666, at action iteration: 1056. (total of 1059 actions, max excludes first 1056 actions)
    > Max action efficiency: 0.0, at action iteration: 1056. (total of 1059 actions, max excludes first 1056 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Choosing a snapshot from the following options:{'trial_success_rate_best_value': 0.30666666666666664, 'trial_success_rate_best_index': 6477, 'grasp_success_rate_best_value': 0.9444444444444444, 'grasp_success_rate_best_index': 18688, 'place_success_rate_best_value': 1.0, 'place_success_rate_best_index': 8939, 'action_efficiency_best_value': 0.108, 'action_efficiency_best_index': 2758}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-11-01-28-16_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': -inf, 'trial_success_rate_best_index': None, 'grasp_success_rate_best_value': 1.0, 'grasp_success_rate_best_index': 1056, 'place_success_rate_best_value': 0.6666666666666666, 'place_success_rate_best_index': 1056, 'action_efficiency_best_value': 0.0, 'action_efficiency_best_index': 1056}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.30666666666666664, 'trial_success_rate_best_index': 6477, 'grasp_success_rate_best_value': 0.9444444444444444, 'grasp_success_rate_best_index': 18688, 'place_success_rate_best_value': 1.0, 'place_success_rate_best_index': 8939, 'action_efficiency_best_value': 0.108, 'action_efficiency_best_index': 2758}


    > Trial logging complete: 101 --------------------------------------------------------------
    > STACK:  trial: 101 actions/partial: 3.890909090909091  actions/full stack: 39.629629629629626 (lower is better)  Grasp Count: 6, grasp success rate: 1.0 place_on_stack_rate: 45.833333333333336 place_attempts: 6  partial_stack_successes: 275  stack_successes: 27 trial_success_rate: 0.26732673267326734 stack
    > goal: [1 3] current_height: 2
    > trial_complete_indices: [   8.   19.   27.   41.   50.   56.   59.   69.   77.   84.   98.  107.
    >   124.  134.  146.  151.  164.  167.  191.  198.  213.  225.  233.  244.
    >   253.  264.  273.  285.  308.  320.  333.  341.  343.  352.  361.  372.
    >   397.  408.  419.  429.  435.  445.  448.  455.  465.  480.  492.  509.
    >   519.  527.  536.  545.  558.  570.  573.  595.  600.  611.  622.  642.
    >   649.  666.  677.  684.  692.  700.  703.  717.  723.  729.  740.  752.
    >   760.  771.  776.  791.  802.  813.  819.  828.  840.  853.  864.  877.
    >   886.  896.  901.  910.  922.  935.  945.  957.  959. 1001. 1008. 1019.
    >  1027. 1036. 1046. 1056. 1069.]
    > Max trial success rate: 0.27, at action iteration: 1066. (total of 1068 actions, max excludes first 1066 actions)
    > /home/ahundt/src/real_good_robot/plot.py:136: RuntimeWarning: invalid value encountered in double_scalars
    >   success_rate[i] = float(successes.sum()) / float(grasp_count) if grasp_count > 0 else 0.0
    > Max grasp success rate: 1.0, at action iteration: 1066. (total of 1068 actions, max excludes first 1066 actions)
    > Max place success rate: 1.0, at action iteration: 1066. (total of 1069 actions, max excludes first 1066 actions)
    > Max action efficiency: 0.0, at action iteration: 1066. (total of 1069 actions, max excludes first 1066 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Choosing a snapshot from the following options:{'action_efficiency_best_index': 2758, 'action_efficiency_best_value': 0.108, 'grasp_success_rate_best_index': 18688, 'grasp_success_rate_best_value': 0.9444444444444444, 'place_success_rate_best_index': 8939, 'place_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 6477, 'trial_success_rate_best_value': 0.30666666666666664}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-11-10-22-05_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.27, 'trial_success_rate_best_index': 1066, 'grasp_success_rate_best_value': 1.0, 'grasp_success_rate_best_index': 1066, 'place_success_rate_best_value': 1.0, 'place_success_rate_best_index': 1066, 'action_efficiency_best_value': 0.0, 'action_efficiency_best_index': 1066}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-07-14-07-53_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'action_efficiency_best_index': 2758, 'action_efficiency_best_value': 0.108, 'grasp_success_rate_best_index': 18688, 'grasp_success_rate_best_value': 0.9444444444444444, 'place_success_rate_best_index': 8939, 'place_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 6477, 'trial_success_rate_best_value': 0.30666666666666664}

    manual action efficiency calculation: 100 trials * 6 ideal actions per trial / 1069 actions = 0.561


SIM STACK - Task Progress aka progress only - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - workstation named spot 2020-06-08
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training
Commit: 36a0c6a8cfd6c0d8a087f0b647814575054faedd  release tag:v0.16.3
GPU 2, Tab 2, port 19990, left v-rep window, v-rep tab 9

    > First model test result (second model pending)
    > ± '/home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training/2020-06-12-03-47-07_Sim-Stack-Two-Step-Reward-Testing/best_stats.json' 
    > {"action_efficiency_best_index": 1542, "action_efficiency_best_value": 0.38132295719844356, "grasp_success_rate_best_index": 1542, "grasp_success_rate_best_value": 0.7957992998833139, "place_success_rate_best_index": 1544, "place_success_rate_best_value": 0.7259475218658892, "trial_success_rate_best_index": 1542, "trial_success_rate_best_value": 0.98}

    > Trial logging complete: 101 --------------------------------------------------------------
    > check_stack() stack_height: 1.0231710310697297 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.937125748502994  actions/full stack: 13.01980198019802 (lower is better)  Grasp Count: 735, grasp success rate: 0.7877551020408163 place_on_stack_rate: 0.5768566493955095 place_attempts: 579  partial_stack_successes: 334  stack_successes: 101 trial_success_rate: 1.0 stack goal: None current_height: 1.0231710310697297
    > trial_complete_indices: [   6.   20.   46.   50.   63.   67.   73.   87.   99.  111.  117.  152.
    >   158.  166.  181.  187.  197.  205.  209.  219.  232.  242.  250.  265.
    >   269.  278.  285.  293.  320.  326.  345.  355.  361.  373.  399.  406.
    >   452.  466.  493.  499.  507.  515.  532.  540.  546.  550.  557.  565.
    >   571.  577.  593.  601.  610.  618.  639.  643.  657.  664.  672.  678.
    >   700.  707.  723.  734.  750.  761.  770.  776.  813.  819.  823.  874.
    >   900.  910.  915.  928.  964.  968.  980.  988. 1014. 1023. 1027. 1035.
    >  1039. 1070. 1098. 1113. 1127. 1138. 1148. 1168. 1184. 1194. 1200. 1209.
    >  1225. 1237. 1261. 1305. 1314.]
    > Max trial success rate: 1.0, at action iteration: 1311. (total of 1313 actions, max excludes first 1311 actions)
    > Max grasp success rate: 0.7885402455661664, at action iteration: 1311. (total of 1313 actions, max excludes first 1311 actions)
    > Max place success rate: 0.7461139896373057, at action iteration: 1311. (total of 1314 actions, max excludes first 1311 actions)
    > Max action efficiency: 0.4622425629290618, at action iteration: 1313. (total of 1314 actions, max excludes first 1311 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing-Sim-Stack-Two-Step-Reward-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training/2020-06-12-10-30-14_Sim-Stack-Two-Step-Reward-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1311, 'grasp_success_rate_best_value': 0.7885402455661664, 'grasp_success_rate_best_index': 1311, 'place_success_rate_best_value': 0.7461139896373057, 'place_success_rate_best_index': 1311, 'action_efficiency_best_value': 0.4622425629290618, 'action_efficiency_best_index': 1313}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-08-17-36-39_Sim-Stack-Two-Step-Reward-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8627450980392157, 'trial_success_rate_best_index': 17335, 'grasp_success_rate_best_value': 0.8943396226415095, 'grasp_success_rate_best_index': 18852, 'place_success_rate_best_value': 0.8398268398268398, 'place_success_rate_best_index': 17013, 'action_efficiency_best_value': 0.624, 'action_efficiency_best_index': 17020}



Resumed run
------------
RESUME pass 1 run (formerly gpu 1) on gpu 3, see /home/ahundt/src/real_good_robot/logs/2020-05-28-12-10-18_Sim-Rows-SPOT-Trial-Reward-Training near the top of this file














PASS 4 
========================================


PUSHING AND GRASPING WITH TRIAL REWARD & SAVE ALL MODELS ACCORDING TO BEST STATS - 2020-06-12
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000
Commit: 60c816e2539f9b105f622132d1a6e22dc572caff  release tag:v0.16.4
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


RESUME: ± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000 --resume /home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
RESUME COMMIT: d0294ba8f84feea20ade3f3ec7ba9ba96a6b9371 (plotting crash bugfix)

± '/home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-13-07-52-11_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Testing/best_stats.json' 
Random testing:
{"grasp_action_efficiency_best_index": 1562, "grasp_action_efficiency_best_value": 0.6165172855313701, "grasp_success_rate_best_index": 1562, "grasp_success_rate_best_value": 0.7351145038167939, "trial_success_rate_best_index": 1562, "trial_success_rate_best_value": 0.98989898989899}

testing challenging arrangements:± 
'/home/ahundt/src/real_good_robot/logs/2020-06-12-00-36-00_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-13-15-04-48_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/best_stats.json' 
{"grasp_action_efficiency_best_index": 1442, "grasp_action_efficiency_best_value": 0.3393476752255378, "grasp_success_rate_best_index": 1442, "grasp_success_rate_best_value": 0.443336355394379, "senarios_100_percent_complete": 6, "trial_success_rate_best_index": 1441, "trial_success_rate_best_value": 0.9541284403669725}



PUSHING AND GRASPING WITH TASK PROGRESS & SAVE ALL MODELS ACCORDING TO BEST STATS - 2020-06-13
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay --tcp_port 19990 --common_sense --future_reward_discount 0.65  --random_actions  --max_train_actions 5000
Commit: 60c816e2539f9b105f622132d1a6e22dc572caff  release tag:v0.16.4
Creating data logging session: 
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7




Parameter sensitivity experiment - SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.5, 1, 1 - workstation named spot 2020-06-12
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-11-23-41-01_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: ff54ed3ae8b700b12433897e680362675cd31013  release tag:push_r_weight_0.5_v1
GPU 1, Tab 1, port 19998, center left v-rep window, v-rep tab 8











ANY OBJECT SIM STACK  - Trial Reward SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-03
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --trial_reward --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: 
Commit: 60c816e2539f9b105f622132d1a6e22dc572caff  release tag:v0.16.4
GPU 2, Tab 2, port 19999, right v-rep window, v-rep tab 10






Resumed run
------------
RESUME pass 1 run (formerly gpu 0) on gpu 3, see /home/ahundt/src/real_good_robot/logs/2020-05-28-12-09-32_Sim-Stack-SPOT-Trial-Reward-Training near the top of this file











PASS 5 - efficientnet
=======




PUSHING AND GRASPING WITH TRIAL REWARD & SAVE ALL MODELS ACCORDING TO BEST STATS - EFFICIENTNET 1 dilation - 2020-06-26
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000 --nn efficientnet --num_dilation 1
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


    > Trial logging complete: 110 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 0.746463 (push), 1.726852 (grasp)
    > Action: grasp at (4, 92, 83)
    > Training loss: 0.057178
    > prev_height: 0.0 max_z: 0.05111149809658745 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > Grasp Count: 986, grasp success rate: 0.513184584178499
    > trial_complete_indices: [  6.  13.  17.  28.  39.  54.  61.  70.  79.  85.  96. 106. 118. 132.
    >  146. 156. 163. 170. 178. 187. 192. 199. 207. 210. 212. 218. 222. 229.
    >  233. 240. 250. 264. 279. 286. 296. 308. 322. 337. 349. 360. 370. 377.
    >  390. 398. 404. 415. 424. 430. 438. 444. 454. 463. 473. 481. 487. 495.
    >  503. 508. 516. 523. 530. 535. 541. 546. 551. 556. 562. 566. 575. 583.
    >  593. 606. 615. 628. 641. 651. 660. 670. 682. 688. 698. 714. 730. 744.
    >  756. 767. 775. 781. 805. 813. 821. 827. 836. 847. 854. 860. 865. 871.
    >  880. 889. 897. 909. 916. 924. 936. 942. 953. 965. 979. 990.]
    > Max trial success rate: 1.0, at action iteration: 987. (total of 989 actions, max excludes first 987 actions)
    > max trial successes: 110.0
    > individual_arrangement_trial_success_rate: [1.  1.  0.9 1.  1.  1.  1.  1.  1.  1.  0.9]
    > senarios_100_percent_complete: 9
    > Max grasp success rate: 0.513733468972533, at action iteration: 987. (total of 989 actions, max excludes first 987 actions)
    > Max grasp action efficiency: 0.5116514690982776, at action iteration: 987. (total of 990 actions, max excludes first 987 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/grasp-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements-Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/best_stats.json
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 987, 'senarios_100_percent_complete': 9, 'grasp_success_rate_best_value': 0.513733468972533, 'grasp_success_rate_best_index': 987, 'grasp_action_efficiency_best_value': 0.5116514690982776, 'grasp_action_efficiency_best_index': 987}
    > Choosing a snapshot from the following options:{'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 675, 'grasp_success_rate_best_value': 0.8714285714285714, 'grasp_success_rate_best_index': 4705, 'grasp_action_efficiency_best_value': 0.854, 'grasp_action_efficiency_best_index': 4705}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-27-18-18-07_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 987, 'senarios_100_percent_complete': 9, 'grasp_success_rate_best_value': 0.513733468972533, 'grasp_success_rate_best_index': 987, 'grasp_action_efficiency_best_value': 0.5116514690982776, 'grasp_action_efficiency_best_index': 987}
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-27-13-00-19_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1133, 'grasp_success_rate_best_value': 0.8499558693733451, 'grasp_success_rate_best_index': 1133, 'grasp_action_efficiency_best_value': 0.8499558693733451, 'grasp_action_efficiency_best_index': 1133}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-10-40_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 675, 'grasp_success_rate_best_value': 0.8714285714285714, 'grasp_success_rate_best_index': 4705, 'grasp_action_efficiency_best_value': 0.854, 'grasp_action_efficiency_best_index': 4705}




PUSHING AND GRASPING WITH TRIAL REWARD & SAVE ALL MODELS ACCORDING TO BEST STATS - EFFICIENTNET 1 dilation - 2020-06-28
--------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 10 --push_rewards --experience_replay --explore_rate_decay  --tcp_port 19990 --common_sense --trial_reward --future_reward_discount 0.65 --random_actions --max_train_actions 5000 --nn efficientnet --num_dilation 1
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


    > Trial logging complete: 110 --------------------------------------------------------------
    > Running two step backprop()
    > Primitive confidence scores: 1.113376 (push), 1.805528 (grasp)
    > Action: grasp at (13, 139, 115)
    > Training loss: 0.197310
    > Executing: grasp at (-0.494000, 0.054000, 0.050216) orientation: 5.105088
    > gripper position: 0.0528782494366169
    > gripper position: 0.034795910120010376
    > gripper position: 0.033892154693603516
    > gripper position: 0.03291165828704834
    > Grasp successful: False
    > prev_height: 0.0 max_z: 0.0667136022755871 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > Grasp Count: 852, grasp success rate: 0.5880281690140845
    > trial_complete_indices: [  8.  18.  33.  41.  48.  58.  69.  84.  95. 101. 108. 120. 127. 134.
    >  140. 152. 160. 169. 179. 191. 196. 202. 208. 214. 221. 227. 232. 236.
    >  241. 255. 268. 275. 286. 301. 316. 328. 343. 358. 368. 378. 384. 391.
    >  400. 408. 420. 426. 434. 441. 449. 455. 464. 472. 481. 492. 501. 509.
    >  518. 527. 538. 546. 551. 555. 559. 566. 570. 576. 580. 586. 590. 594.
    >  606. 615. 624. 632. 640. 647. 655. 662. 670. 682. 696. 709. 721. 733.
    >  753. 765. 780. 794. 809. 823. 829. 837. 847. 858. 866. 873. 883. 896.
    >  910. 916. 924. 932. 941. 947. 953. 963. 969. 975. 984. 992.]
    > Max trial success rate: 1.0, at action iteration: 989. (total of 991 actions, max excludes first 989 actions)
    > max trial successes: 110.0
    > individual_arrangement_trial_success_rate: [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.9]
    > senarios_100_percent_complete: 10
    > Max grasp success rate: 0.5882352941176471, at action iteration: 990. (total of 991 actions, max excludes first 989 actions)
    > Max grasp action efficiency: 0.506572295247725, at action iteration: 991. (total of 992 actions, max excludes first 989 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/grasp-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements-Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements/best_stats.json
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 989, 'senarios_100_percent_complete': 10, 'grasp_success_rate_best_value': 0.5882352941176471, 'grasp_success_rate_best_index': 990, 'grasp_action_efficiency_best_value': 0.506572295247725, 'grasp_action_efficiency_best_index': 991}
    > Choosing a snapshot from the following options:{'trial_success_rate_best_value': 1.0232558139534884, 'trial_success_rate_best_index': 4999, 'grasp_success_rate_best_value': 0.8843813387423936, 'grasp_success_rate_best_index': 4768, 'grasp_action_efficiency_best_value': 0.872, 'grasp_action_efficiency_best_index': 4768}
    > Evaluating trial_success_rate_best_value
    > Shapshot chosen: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/models/snapshot.reinforcement_trial_success_rate_best_value.pth
    > Challenging Arrangements Preset Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-29-13-27-18_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Challenging-Arrangements
    > Challenging Arrangements Preset Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 989, 'senarios_100_percent_complete': 10, 'grasp_success_rate_best_value': 0.5882352941176471, 'grasp_success_rate_best_index': 990, 'grasp_action_efficiency_best_value': 0.506572295247725, 'grasp_action_efficiency_best_index': 991}
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training/2020-06-29-08-15-52_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1122, 'grasp_success_rate_best_value': 0.8556053811659193, 'grasp_success_rate_best_index': 1122, 'grasp_action_efficiency_best_value': 0.8502673796791443, 'grasp_action_efficiency_best_index': 1122}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-28-10-45-13_Sim-Push-and-Grasp-SPOT-Trial-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 1.0232558139534884, 'trial_success_rate_best_index': 4999, 'grasp_success_rate_best_value': 0.8843813387423936, 'grasp_success_rate_best_index': 4768, 'grasp_action_efficiency_best_value': 0.872, 'grasp_action_efficiency_best_index': 4768}





ANY OBJECT SIM STACK  - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-26
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/toys --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-13-25_Sim-Stack-Two-Step-Reward-Masked-Training                                                                                                                                                                     
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 1, Tab 1, port 19998, right center v-rep window, v-rep tab 8



    > Trial logging complete: 101 --------------------------------------------------------------
    > STACK:  trial: 101 actions/partial: 29.161125319693095  actions/full stack: 438.53846153846155 (lower is better)  Grasp Count: 6677, grasp success rate: 0.5800509210723379 place_on_stack_rate: 0.1013215859030837 place_attempts: 3859  partial_stack_successes: 391  stack_successes: 26 trial_success_rate: 0.25742574257425743 stack goal: None current_height: 1.3412568889607048
    > trial_complete_indices: [  225.   366.   460.   571.   752.   835.   966.  1122.  1221.  1364.
    >   1492.  1545.  1680.  1741.  1829.  1895.  2040.  2189.  2443.  2554.
    >   2714.  2753.  2810.  2856.  2985.  3120.  3295.  3416.  3508.  3572.
    >   3669.  3732.  3862.  3938.  4024.  4085.  4112.  4175.  4186.  4342.
    >   4492.  4677.  4749.  4904.  5083.  5167.  5297.  5412.  5581.  5698.
    >   5896.  5922.  6073.  6167.  6269.  6355.  6659.  6714.  6743.  6894.
    >   6975.  7053.  7116.  7211.  7342.  7418.  7519.  7549.  7796.  7820.
    >   7858.  8041.  8109.  8183.  8428.  8638.  8894.  9005.  9114.  9337.
    >   9464.  9686.  9738.  9817.  9961. 10015. 10145. 10193. 10328. 10366.
    >  10445. 10548. 10626. 10742. 10764. 10848. 10865. 11031. 11197. 11315.
    >  11401.]
    > Max trial success rate: 0.26, at action iteration: 11398. (total of 11400 actions, max excludes first 11398 actions)
    > Max grasp success rate: 0.5801618219958046, at action iteration: 11398. (total of 11400 actions, max excludes first 11398 actions)
    > Max place success rate: 0.5263492063492063, at action iteration: 11398. (total of 11401 actions, max excludes first 11398 actions)
    > Max action efficiency: 0.015265836111598525, at action iteration: 11398. (total of 11401 actions, max excludes first 11398 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-02-14-53-00_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-13-25_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-30-05-17-35_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.47, 'trial_success_rate_best_index': 13484, 'grasp_success_rate_best_value': 0.7247529834466829, 'grasp_success_rate_best_index': 13484, 'place_success_rate_best_value': 0.5312719606465214, 'place_success_rate_best_index': 13486, 'action_efficiency_best_value': 0.027588252743992882, 'action_efficiency_best_index': 13486}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-13-25_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.25, 'trial_success_rate_best_index': 13316, 'grasp_success_rate_best_value': 0.8694029850746269, 'grasp_success_rate_best_index': 18482, 'place_success_rate_best_value': 0.6090909090909091, 'place_success_rate_best_index': 8898, 'action_efficiency_best_value': 1.164, 'action_efficiency_best_index': 6812}









SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-26
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-17-08_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 2, Tab 2, port 19999, right center v-rep window, v-rep tab 9


    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.051130634964013114 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > prev_height: 1.0 max_z: 1.0226126992802622 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
    > check_stack() stack_height: 1.0226126992802622 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.0235690235690234  actions/full stack: 8.98 (lower is better)  Grasp Count: 488, grasp success rate: 0.8422131147540983 place_on_stack_rate: 0.724390243902439 place_attempts: 410  partial_stack_successes: 297  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: None current_height: 1.0226126992802622
    > trial_complete_indices: [  6.  20.  32.  38.  47.  53.  61.  69.  73.  78.  88.  93.  99. 105.
    >  113. 119. 125. 137. 145. 149. 155. 159. 171. 186. 194. 198. 203. 214.
    >  224. 230. 236. 244. 253. 259. 265. 275. 281. 287. 293. 301. 311. 322.
    >  330. 342. 350. 361. 368. 374. 383. 390. 398. 402. 418. 425. 433. 441.
    >  445. 453. 457. 471. 479. 485. 492. 502. 550. 559. 575. 581. 587. 595.
    >  599. 606. 616. 628. 634. 638. 649. 656. 666. 674. 680. 686. 691. 700.
    >  707. 711. 717. 729. 735. 743. 753. 762. 769. 775. 785. 803. 815. 823.
    >  880. 889. 897.]
    > Max trial success rate: 0.99, at action iteration: 894. (total of 896 actions, max excludes first 894 actions)
    > Max grasp success rate: 0.8436213991769548, at action iteration: 894. (total of 896 actions, max excludes first 894 actions)
    > Max place success rate: 0.8484107579462102, at action iteration: 894. (total of 897 actions, max excludes first 894 actions)
    > Max action efficiency: 0.6711409395973155, at action iteration: 896. (total of 897 actions, max excludes first 894 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-10-36-48_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-17-08_Sim-Stack-Two-Step-Reward-Masked-Training/2020-06-30-06-33-03_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results: 
    >  {'trial_success_rate_best_value': 0.99, 'trial_success_rate_best_index': 823, 'grasp_success_rate_best_value': 0.9133489461358314, 'grasp_success_rate_best_index': 823, 'place_success_rate_best_value': 0.8513853904282116, 'place_success_rate_best_index': 823, 'action_efficiency_best_value': 0.7290400972053463, 'action_efficiency_best_index': 825}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-17-08_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results: 
    >  {'trial_success_rate_best_value': 0.9054054054054054, 'trial_success_rate_best_index': 15101, 'grasp_success_rate_best_value': 0.9683794466403162, 'grasp_success_rate_best_index': 12884, 'place_success_rate_best_value': 0.9267241379310345, 'place_success_rate_best_index': 13640, 'action_efficiency_best_value': 0.864, 'action_efficiency_best_index': 13081}





SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-26
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-18-44_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10

    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05110832959176721 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: False | row_size: 1 | blocks: []
    > check_stack() stack_height: 1 stack matches current goal: True partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 5.036144578313253  actions/full stack: 12.666666666666666 (lower is better)  Grasp Count: 677, grasp success rate: 0.8552437223042836 place_on_stack_rate: 0.43154246100519933 place_attempts: 577  partial_stack_successes: 249  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: [2 1] current_height: 1
    > trial_complete_indices: [   4.    8.   14.   22.   34.   51.   55.   59.   63.   78.   88.   98.
    >   105.  139.  143.  164.  166.  188.  195.  214.  218.  224.  232.  237.
    >   276.  282.  287.  307.  340.  344.  352.  364.  368.  372.  390.  398.
    >   402.  419.  421.  425.  450.  460.  468.  490.  494.  502.  508.  522.
    >   524.  529.  541.  547.  661.  713.  717.  754.  774.  782.  804.  816.
    >   822.  829.  834.  838.  842.  847.  849.  856.  885.  889.  894.  932.
    >   934.  953.  983. 1006. 1010. 1018. 1030. 1040. 1044. 1078. 1110. 1118.
    >  1136. 1140. 1151. 1153. 1161. 1167. 1183. 1189. 1195. 1214. 1218. 1220.
    >  1226. 1236. 1240. 1244. 1253.]
    > Max trial success rate: 0.98, at action iteration: 1250. (total of 1252 actions, max excludes first 1250 actions)
    > Max grasp success rate: 0.8562962962962963, at action iteration: 1250. (total of 1252 actions, max excludes first 1250 actions)
    > Max place success rate: 0.7013888888888888, at action iteration: 1250. (total of 1253 actions, max excludes first 1250 actions)
    > Max action efficiency: 0.4896, at action iteration: 1252. (total of 1253 actions, max excludes first 1250 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-18-44_Sim-Rows-Two-Step-Reward-Masked-Training/2020-06-30-14-25-16_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 1250, 'grasp_success_rate_best_value': 0.8562962962962963, 'grasp_success_rate_best_index': 1250, 'place_success_rate_best_value': 0.7013888888888888, 'place_success_rate_best_index': 1250, 'action_efficiency_best_value': 0.4896, 'action_efficiency_best_index': 1252}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-26-15-18-44_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.5869565217391305, 'trial_success_rate_best_index': 13103, 'grasp_success_rate_best_value': 0.7921146953405018, 'grasp_success_rate_best_index': 15530, 'place_success_rate_best_value': 0.7102803738317757, 'place_success_rate_best_index': 15717, 'action_efficiency_best_value': 0.708, 'action_efficiency_best_index': 15733}















SIM STACK - Task Progress SPOT-Q MASKED - RANDOM ACTIONS - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --check_z_height --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-27-56_Sim-Stack-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 2, Tab 2, port 19999, right center v-rep window, v-rep tab 9


    > Trial logging complete: 101 --------------------------------------------------------------
    > check_stack() stack_height: 1.0228815123259785 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.623342175066313  actions/full stack: 13.797979797979798 (lower is better)  Grasp Count: 748, grasp success rate: 0.8275401069518716 place_on_stack_rate: 0.610032362459547 place_attempts: 618  partial_stack_successes: 377  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: None current_height: 1.0228815123259785
    > trial_complete_indices: [  10.  158.  178.  186.  198.  214.  223.  231.  235.  241.  253.  259.
    >   265.  285.  307.  311.  359.  365.  373.  395.  405.  416.  424.  432.
    >   442.  449.  457.  463.  489.  536.  566.  572.  576.  582.  602.  609.
    >   613.  642.  648.  731.  738.  745.  751.  760.  764.  770.  777.  783.
    >   790.  796.  816.  823.  829.  833.  849.  870.  888.  898.  908.  920.
    >   941.  953.  970.  977. 1009. 1015. 1028. 1034. 1040. 1050. 1061. 1071.
    >  1079. 1086. 1092. 1107. 1121. 1127. 1133. 1142. 1156. 1167. 1175. 1181.
    >  1194. 1198. 1211. 1222. 1229. 1235. 1241. 1261. 1270. 1277. 1303. 1335.
    >  1341. 1347. 1355. 1361. 1365.]
    > Max trial success rate: 0.97, at action iteration: 1362. (total of 1364 actions, max excludes first 1362 actions)
    > Max grasp success rate: 0.8284182305630027, at action iteration: 1362. (total of 1364 actions, max excludes first 1362 actions)
    > Max place success rate: 0.7828200972447326, at action iteration: 1362. (total of 1365 actions, max excludes first 1362 actions)
    > Max action efficiency: 0.43612334801762115, at action iteration: 1364. (total of 1365 actions, max excludes first 1362 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing-Sim-Stack-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-14-12-00_Sim-Stack-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-27-56_Sim-Stack-Two-Step-Reward-Masked-Training/2020-07-04-08-05-41_Sim-Stack-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 1321, 'grasp_success_rate_best_value': 0.8487394957983193, 'grasp_success_rate_best_index': 1321, 'place_success_rate_best_value': 0.7467105263157895, 'place_success_rate_best_index': 1321, 'action_efficiency_best_value': 0.45420136260408783, 'action_efficiency_best_index': 1321}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-27-56_Sim-Stack-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.8103448275862069, 'trial_success_rate_best_index': 6022, 'grasp_success_rate_best_value': 0.9153846153846154, 'grasp_success_rate_best_index': 12393, 'place_success_rate_best_value': 0.8297872340425532, 'place_success_rate_best_index': 8789, 'action_efficiency_best_value': 0.624, 'action_efficiency_best_index': 8820}





SIM ROW - Task Progress SPOT-Q MASKED - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-06-30
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 19990 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-46-54_Sim-Rows-Two-Step-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 0, Tab 0, port 19990, left v-rep window, v-rep tab 7


    > Trial logging complete: 101 --------------------------------------------------------------
    > prev_height: 0.0 max_z: 0.05112317412691904 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
    > check_row: True | row_size: 2 | blocks: ['blue' 'red']
    > check_stack() stack_height: 2 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
    > STACK:  trial: 101 actions/partial: 3.7033492822966507  actions/full stack: 7.818181818181818 (lower is better)  Grasp Count: 411, grasp success rate: 0.8880778588807786 place_on_stack_rate: 0.5757575757575758 place_attempts: 363  partial_stack_successes: 209  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: [3 0] current_height: 2
    > trial_complete_indices: [  2.  16.  24.  80.  82.  86. 100. 105. 109. 113. 120. 139. 149. 162.
    >  164. 172. 176. 187. 191. 197. 203. 208. 210. 214. 216. 220. 230. 234.
    >  238. 242. 251. 253. 257. 267. 275. 279. 284. 290. 312. 318. 324. 328.
    >  334. 338. 344. 349. 355. 359. 363. 368. 372. 380. 382. 388. 394. 400.
    >  404. 409. 413. 415. 419. 425. 440. 446. 454. 458. 470. 474. 476. 482.
    >  588. 592. 594. 596. 600. 609. 611. 615. 621. 642. 650. 654. 662. 670.
    >  680. 685. 689. 693. 698. 702. 704. 706. 719. 723. 730. 734. 738. 746.
    >  750. 760. 773.]
    > Max trial success rate: 0.98, at action iteration: 770. (total of 772 actions, max excludes first 770 actions)
    > Max grasp success rate: 0.8899755501222494, at action iteration: 770. (total of 772 actions, max excludes first 770 actions)
    > Max place success rate: 0.787292817679558, at action iteration: 770. (total of 773 actions, max excludes first 770 actions)
    > Max action efficiency: 0.7636363636363637, at action iteration: 770. (total of 773 actions, max excludes first 770 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing-Sim-Rows-Two-Step-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-46-54_Sim-Rows-Two-Step-Reward-Masked-Training/2020-07-04-12-12-29_Sim-Rows-Two-Step-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 770, 'grasp_success_rate_best_value': 0.8899755501222494, 'grasp_success_rate_best_index': 770, 'place_success_rate_best_value': 0.787292817679558, 'place_success_rate_best_index': 770, 'action_efficiency_best_value': 0.7636363636363637, 'action_efficiency_best_index': 770}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-06-30-17-46-54_Sim-Rows-Two-Step-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7446808510638298, 'trial_success_rate_best_index': 18005, 'grasp_success_rate_best_value': 0.8555555555555555, 'grasp_success_rate_best_index': 16054, 'place_success_rate_best_value': 0.7981651376146789, 'place_success_rate_best_index': 19487, 'action_efficiency_best_value': 1.008, 'action_efficiency_best_index': 19499}





SIM ROW - SPOT STANDARD Trial rtrial Task Progress - TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - EFFICIENTNET 1 dilation - workstation named spot 2020-07-01
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --check_row --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --common_sense --nn efficientnet --num_dilation 1 --trial_reward
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2020-07-01-17-41-43_Sim-Rows-SPOT-Trial-Reward-Masked-Training
Commit: cca5887217884d862167edbf31ffaf4d1d21a863  release tag:v0.16.5
GPU 3, Tab 3, port 20000, right v-rep window, v-rep tab 10

    > Trial logging complete: 101 --------------------------------------------------------------
    > STACK:  trial: 101 actions/partial: 3.719665271966527  actions/full stack: 9.98876404494382 (lower is better)  Grasp Count: 474, grasp success rate: 0.9008438818565401 place_on_stack_rate: 0.5759036144578313 place_attempts: 415  partial_stack_successes: 239  stack_successes: 89 trial_success_rate: 0.8811881188118812 stack goal: [0 3] current_height: 2
    > trial_complete_indices: [  2.   9.  15.  20.  24.  32.  55.  62.  67.  71.  83. 103. 115. 117.
    >  125. 133. 141. 147. 158. 164. 174. 183. 193. 199. 208. 214. 234. 238.
    >  242. 259. 265. 280. 286. 290. 296. 304. 308. 319. 325. 333. 341. 345.
    >  368. 372. 378. 382. 388. 402. 418. 442. 448. 454. 458. 467. 471. 473.
    >  481. 492. 496. 505. 509. 515. 519. 540. 548. 566. 570. 577. 583. 589.
    >  593. 599. 601. 632. 640. 648. 671. 675. 711. 719. 730. 738. 742. 748.
    >  750. 752. 758. 764. 768. 774. 783. 821. 825. 829. 837. 846. 854. 860.
    >  870. 880. 888.]
    > Max trial success rate: 0.88, at action iteration: 885. (total of 887 actions, max excludes first 885 actions)
    > Max grasp success rate: 0.902542372881356, at action iteration: 885. (total of 887 actions, max excludes first 885 actions)
    > Max place success rate: 0.7198067632850241, at action iteration: 885. (total of 888 actions, max excludes first 885 actions)
    > Max action efficiency: 0.6169491525423729, at action iteration: 885. (total of 888 actions, max excludes first 885 actions)
    > saving trial success rate: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/trial-success-rate.log.csv
    > saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/grasp-success-rate.log.csv
    > saving place success rate: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/place-success-rate.log.csv
    > saving action efficiency: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/transitions/action-efficiency.log.csv
    > saving plot: 2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing-Sim-Rows-SPOT-Trial-Reward-Masked-Testing_success_plot.png
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/data/best_stats.json
    > saving best stats to: /home/ahundt/src/real_good_robot/logs/2020-07-05-17-34-39_Sim-Rows-SPOT-Trial-Reward-Masked-Testing/best_stats.json
    > Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-07-01-17-41-43_Sim-Rows-SPOT-Trial-Reward-Masked-Training/2020-07-05-13-47-48_Sim-Rows-SPOT-Trial-Reward-Masked-Testing
    > Random Testing results:
    >  {'trial_success_rate_best_value': 0.9, 'trial_success_rate_best_index': 772, 'grasp_success_rate_best_value': 0.8776978417266187, 'grasp_success_rate_best_index': 772, 'place_success_rate_best_value': 0.7471910112359551, 'place_success_rate_best_index': 772, 'action_efficiency_best_value': 0.7072538860103627, 'action_efficiency_best_index': 772}
    > Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2020-07-01-17-41-43_Sim-Rows-SPOT-Trial-Reward-Masked-Training
    > Training results:
    >  {'trial_success_rate_best_value': 0.7078651685393258, 'trial_success_rate_best_index': 19445, 'grasp_success_rate_best_value': 0.8555555555555555, 'grasp_success_rate_best_index': 18899, 'place_success_rate_best_value': 0.7663551401869159, 'place_success_rate_best_index': 19900, 'action_efficiency_best_value': 0.828, 'action_efficiency_best_index': 19904}





===================================
POST GOOD ROBOT 2021-02-13



DEPTH CHANNEL HISTORY, DENSENET - SIM UNSTACKING - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - PROGRESS REWARD - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-13
----------------------------------------------------------------------------------------

x ± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_train_actions 40000 --random_actions --task_type unstacking --depth_channels_history 
x PUSH TOPPLE DETECTION BUG, CANCELLED: Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-15-35-04_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
x PUSH TOPPLE DETECTION BUG, CANCELLED: Commit : 5721c9e8fde6d26759d7663cb972e0802fb84207
x Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
x cancelled, push topples deemed success: Commit: 0cd323c2ec8509e3b5f1240897c7c1360824368c
x resume: ± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_train_actions 40000 --random_actions --task_type unstacking --depth_channels_history --resume /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/
x Commit: 81b1e73a4b6248ebedc5443fed0520ff0bebd777
x GPU 0, Tab 0, port 19990, top left v-rep window, v-rep tab 7
x 
x Max trial success rate: 0.28688524590163933, at action iteration: 1101. (total of 1131 actions, max excludes first 500 actions)
x Max grasp success rate: 0.46496815286624205, at action iteration: 1125. (total of 1131 actions, max excludes first 500 actions)
x Max place success rate: 0.9447513812154696, at action iteration: 892. (total of 1132 actions, max excludes first 500 actions)
x Max action efficiency: 0.96, at action iteration: 500. (total of 1132 actions, max excludes first 500 actions)
x saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/transitions/trial-success-rate.log.csv
x saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/transitions/grasp-success-rate.log.csv
x saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/transitions/place-success-rate.log.csv
x saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/transitions/action-efficiency.log.csv
x saving plot: 2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History-Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History_success_plot.png
x saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/data/best_stats.json
x saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/best_stats.json
x Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-13-18-25-59_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
x Training results: 
x  {'trial_success_rate_best_value': 0.28688524590163933, 'trial_success_rate_best_index': 1101, 'grasp_success_rate_best_value': 0.46496815286624205, 'grasp_success_rate_best_index': 1125, 'place_success_rate_best_value': 0.9447513812154696, 'place_success_rate_best_index': 892, 'action_efficiency_best_value': 0.96, 'action_efficiency_best_index': 500}

cancelled due to a bug where a place + topple -> success. It was learning to place and topple the stack really well.
x export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_train_actions 40000 --random_actions --task_type unstacking --depth_channels_history
x Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-22-43-39_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
x Commit: 81b1e73a4b6248ebedc5443fed0520ff0bebd777

export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_train_actions 40000 --random_actions --task_type unstacking --depth_channels_history
GPU 0, Tab 0, port 19990, top left v-rep window, v-rep tab 7



STACKING TEST - SEE training_run_notes_costar.txt entry 2020-12-10-22-40-29_Sim-Stack-SPOT-Trial-Reward-Masked-Training
----------------------------------------------------------------------------------------

Training folder:
Creating data logging session: /media/costar/f5f1f858-3666-4832-beea-b743127f1030/real_good_robot/logs/2020-12-10-22-40-29_Sim-Stack-SPOT-Trial-Reward-Masked-Training


export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --check_z_height --tcp_port 19998 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --depth_channels_history --is_testing --disable_situation_removal --save_visualizations --stack_snapshotfile '/home/ahundt/Downloads/2020-12-10-22-40-29_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Sim-Stack-SPOT-Trial-Reward-Masked/snapshot.reinforcement_trial_success_rate_best_value.pth' --max_test_trials 200
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History
Test Commit: 5721c9e8fde6d26759d7663cb972e0802fb84207
GPU 1, Tab 1, port 19998, top right v-rep window, v-rep tab 7

Test folder:
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History

> STACK:  trial: 101 actions/partial: 4.984848484848484  actions/full stack: 16.45 (lower is better)  Grasp Count: 908, grasp success rate: 0.7995594713656388 place_on_stack_rate: 0.45454545454545453 place_attempts: 726  partial_stack_successes: 330  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: None current_height: 1.022614398164782
> trial_complete_indices: [  19.   29.   35.   41.   51.   57.   69.   78.   84.   90.  100.  110.
>   120.  127.  133.  172.  180.  206.  226.  251.  259.  277.  283.  289.
>   319.  339.  391.  408.  416.  447.  455.  463.  492.  512.  522.  528.
>   552.  558.  565.  571.  590.  598.  605.  611.  615.  626.  637.  660.
>   671.  679.  685.  691.  701.  718.  964.  973.  979. 1007. 1016. 1024.
>  1042. 1049. 1056. 1072. 1080. 1100. 1106. 1115. 1123. 1144. 1154. 1160.
>  1162. 1169. 1185. 1189. 1197. 1219. 1235. 1244. 1264. 1276. 1282. 1293.
>  1301. 1314. 1378. 1403. 1414. 1445. 1467. 1481. 1506. 1525. 1532. 1560.
>  1568. 1574. 1579. 1635. 1644.]
> Max trial success rate: 0.99, at action iteration: 1641. (total of 1643 actions, max excludes first 1641 actions)
> Max grasp success rate: 0.8002207505518764, at action iteration: 1641. (total of 1643 actions, max excludes first 1641 actions)
> Max place success rate: 0.6752717391304348, at action iteration: 1641. (total of 1644 actions, max excludes first 1641 actions)
> Max action efficiency: 0.3692870201096892, at action iteration: 1643. (total of 1644 actions, max excludes first 1641 actions)
> saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/trial-success-rate.log.csv
> saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/grasp-success-rate.log.csv
> saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/place-success-rate.log.csv
> saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/action-efficiency.log.csv
> saving plot: 2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History-Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History_success_plot.png
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/data/best_stats.json
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/best_stats.json
> Choosing a snapshot from the following options:{'trial_success_rate_best_value': 0.97, 'trial_success_rate_best_index': 3219, 'grasp_success_rate_best_value': 0.7554466230936819, 'grasp_success_rate_best_index': 3219, 'place_success_rate_best_value': 0.7312138728323699, 'place_success_rate_best_index': 3219, 'action_efficiency_best_value': 0.4193849021435228, 'action_efficiency_best_index': 3221}
> Evaluating trial_success_rate_best_value
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement_trial_success_rate_best_value.pth does not exist, looking
> for other options.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement_grasp_success_rate_best_value.pth does not exist, looking
> for other options.
> Could not find any best-of models, checking for the basic training models.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement.pth does not exist, looking for other options.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/models/snapshot.reactive.pth does not exist, looking for other options.
> Shapshot chosen:
> Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/2021-02-14-04-49-09_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History
> Random Testing results:
>  {'trial_success_rate_best_value': 0.99, 'trial_success_rate_best_index': 1641, 'grasp_success_rate_best_value': 0.8002207505518764, 'grasp_success_rate_best_index': 1641, 'place_success_rate_best_value': 0.6752717391304348, 'place_success_rate_best_index': 1641, 'action_efficiency_best_value': 0.3692870201096892, 'action_efficiency_best_index': 1643}
> Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-30-37_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History
> Training results:
>  {'trial_success_rate_best_value': 0.97, 'trial_success_rate_best_index': 3219, 'grasp_success_rate_best_value': 0.7554466230936819, 'grasp_success_rate_best_index': 3219, 'place_success_rate_best_value': 0.7312138728323699, 'place_success_rate_best_index': 3219, 'action_efficiency_best_value': 0.4193849021435228, 'action_efficiency_best_index': 3221}



ROW TEST - SEE Creating data logging session: /media/costar/f5f1f858-3666-4832-beea-b743127f1030/real_good_robot/logs/2020-12-27-15-03-09_Sim-Rows-Two-Step-Reward-Masked-Training
----------------------------------------------------------------------------------------

COLLECTING TEST ROW RESULTS WITH OBJECT POSITIONS, 200 test trials (on spot workstation) for language model training:
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --save_visualizations --check_row --tcp_port 19999 --place --future_reward_discount 0.65 --max_train_actions 40000 --random_actions --common_sense --depth_channels_history --is_testing --disable_situation_removal --save_visualizations --row_snapshot_file '/home/ahundt/Downloads/2020-12-27-15-03-09-sim-rows-progress-40k-densenet-model-with-history/2020-12-27-15-03-09-sim-rows-progress-40k/snapshot.reinforcement_action_efficiency_best_value.pth' --max_test_trials 200
Pre-trained model snapshot loaded from: /home/ahundt/Downloads/2020-12-27-15-03-09-sim-rows-progress-40k-densenet-model-with-history/2020-12-27-15-03-09-sim-rows-progress-40k/snapshot.reinforcement_action_efficiency_best_value.pth

Test folder:
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History

> trial_complete_indices: [  4.  14.  18.  24.  30.  32.  40.  44.  48.  52.  74.  80.  90.  94.
>   98. 100. 104. 108. 113. 117. 125. 135. 137. 141. 145. 153. 157. 161.
>  173. 177. 179. 183. 187. 191. 193. 195. 199. 201. 205. 207. 215. 219.
>  231. 235. 239. 243. 247. 252. 256. 260. 262. 268. 272. 277. 281. 285.
>  292. 301. 307. 309. 311. 315. 319. 322. 324. 330. 334. 336. 342. 346.
>  352. 354. 360. 362. 364. 376. 380. 386. 402. 412. 416. 421. 425. 431.
>  438. 442. 447. 453. 457. 462. 472. 479. 481. 491. 493. 497. 501. 505.
>  509. 514. 522.]
> Max trial success rate: 0.98, at action iteration: 519. (total of 521 actions, max excludes first 519 actions)
> Max grasp success rate: 0.9261992619926199, at action iteration: 519. (total of 521 actions, max excludes first 519 actions)
> Max place success rate: 0.8273092369477911, at action iteration: 521. (total of 522 actions, max excludes first 519 actions)
> Max action efficiency: 1.1445086705202312, at action iteration: 521. (total of 522 actions, max excludes first 519 actions)
> saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/trial-success-rate.log.csv
> saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/grasp-success-rate.log.csv
> saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/place-success-rate.log.csv
> saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/action-efficiency.log.csv
> saving plot: 2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History-Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History_success_plot.png
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/data/best_stats.json
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/best_stats.json
> Trial logging complete: 101 --------------------------------------------------------------
> Running two step backprop()
> Primitive confidence scores: 5.244822 (push), 7.168233 (grasp), 7.791639 (place)
> Action: grasp at (8, 104, 183)
> Training loss: 1.425814
> Executing: grasp at (-0.358000, -0.016000, 0.001010) orientation: 3.141593
> gripper position: 0.031022459268569946
> gripper position: 0.026695698499679565
> gripper position: 0.0015523433685302734
> gripper position: -0.022703856229782104
> gripper position: -0.041842639446258545
> moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
> Grasp successful: False
> moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
> prev_height: 0.0 max_z: 0.05112781954041569 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
> main.py: running check_stack_update_goal
> check_row: True | row_size: 3 | blocks: ['blue' 'green' 'yellow']
> check_stack() stack_height: 3 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False
> main.py unstacking_partial_success() DETECTED PROGRESS REVERSAL, grasp action caused stack to topple! Previous Task Progress: 1 Current Task Progress: 3
> main.py() process_actions: place_success: False
> main.py() process_actions: partial_stack_success: True
> STACK:  trial: 101 actions/partial: 2.7526315789473683  actions/full stack: 5.282828282828283 (lower is better)  Grasp Count: 273, grasp success rate: 0.9230769230769231 place_on_stack_rate: 0.76 place_attempts: 250  partial_stack_successes: 190  stack_successes: 99 trial_success_rate: 0.9801980198019802 stack goal: [2 0] current_height: 3
> trial_complete_indices: [  4.  14.  18.  24.  30.  32.  40.  44.  48.  52.  74.  80.  90.  94.
>   98. 100. 104. 108. 113. 117. 125. 135. 137. 141. 145. 153. 157. 161.
>  173. 177. 179. 183. 187. 191. 193. 195. 199. 201. 205. 207. 215. 219.
>  231. 235. 239. 243. 247. 252. 256. 260. 262. 268. 272. 277. 281. 285.
>  292. 301. 307. 309. 311. 315. 319. 322. 324. 330. 334. 336. 342. 346.
>  352. 354. 360. 362. 364. 376. 380. 386. 402. 412. 416. 421. 425. 431.
>  438. 442. 447. 453. 457. 462. 472. 479. 481. 491. 493. 497. 501. 505.
>  509. 514. 522.]
> Max trial success rate: 0.98, at action iteration: 519. (total of 521 actions, max excludes first 519 actions)
> Max grasp success rate: 0.9261992619926199, at action iteration: 519. (total of 521 actions, max excludes first 519 actions)
> Max place success rate: 0.8273092369477911, at action iteration: 521. (total of 522 actions, max excludes first 519 actions)
> Max action efficiency: 1.1445086705202312, at action iteration: 521. (total of 522 actions, max excludes first 519 actions)
> saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/trial-success-rate.log.csv
> saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/grasp-success-rate.log.csv
> saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/place-success-rate.log.csv
> saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/action-efficiency.log.csv
> saving plot: 2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History-Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History_success_plot.png
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/data/best_stats.json
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/best_stats.json
> Choosing a snapshot from the following options:{'trial_success_rate_best_value': 0.985, 'trial_success_rate_best_index': 1047, 'grasp_success_rate_best_value': 0.8953068592057761, 'grasp_success_rate_best_index': 1047, 'place_success_rate_best_value': 0.8785425101214575, 'place_success_rate_best_index': 1047, 'action_efficiency_best_value': 1.157593123209169, 'action_efficiency_best_index': 1049}
> Evaluating trial_success_rate_best_value
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement_trial_success_rate_best_value.pth does not exist, looking for other options.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement_grasp_success_rate_best_value.pth does not exist, looking for other options.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement_action_efficiency_best_value.pth does not exist, looking for
> other options.
> Could not find any best-of models, checking for the basic training models.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/models/snapshot.reinforcement.pth does not exist, looking for other options.
> /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/models/snapshot.reactive.pth does not exist, looking for other options.
> Shapshot chosen:
> Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History/2021-02-13-21-06-05_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History
> Random Testing results:
>  {'trial_success_rate_best_value': 0.98, 'trial_success_rate_best_index': 519, 'grasp_success_rate_best_value': 0.9261992619926199, 'grasp_success_rate_best_index': 519, 'place_success_rate_best_value': 0.8273092369477911, 'place_success_rate_best_index': 521, 'action_efficiency_best_value': 1.1445086705202312, 'action_efficiency_best_index': 521}
> Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-13-16-43-06_Sim-Rows-Two-Step-Reward-Masked-Testing-Three-Step-History
> Training results:
>  {'trial_success_rate_best_value': 0.985, 'trial_success_rate_best_index': 1047, 'grasp_success_rate_best_value': 0.8953068592057761, 'grasp_success_rate_best_index': 1047, 'place_success_rate_best_value': 0.8785425101214575, 'place_success_rate_best_index': 1047, 'action_efficiency_best_value': 1.157593123209169, 'action_efficiency_best_index': 1049}



X DEPTH CHANNEL HISTORY - SIM STACK - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - FULL FEATURED RUN - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-15
X ----------------------------------------------------------------------------------------
X
X Cancelled due to repeated simulator problems with blocks floating in the air.
X
X export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --check_z_height --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 20000 --random_actions --depth_channels_history
X X Cancelled due to observer crash bug with check_z_height: Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-13-19-14-14_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History   
X X Cancelled due to observer crash bug with check_z_height: Commit: 10579082390850375023bc17038570f47c105cc6  release tag:
X Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-09-43_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History
X Commit: 4828f395b44bd742f51e6df8a4cb84a51fceb6d6 release tag:
X GPU 3, Tab 3, port 19998, bottom right v-rep window, v-rep tab 10




DEPTH CHANNEL HISTORY, DENSENET - SIM UNSTACKING - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - PROGRESS REWARD - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-15
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19998 --random_seed 1238 --max_iter 40000 --random_actions --task_type unstacking --depth_channels_history
X Cancelled bc of object pose saving bug: Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-15-12-43-28_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
X Cancelled bc of object pose saving bug: Commit: 5add7dd66366cedad287ba1231c3077edcb7fdf4
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
Commit: 4828f395b44bd742f51e6df8a4cb84a51fceb6d6
The gripper started shaking violently in the sim without any resets.
Resume: ± export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount
0.65 --tcp_port 19998 --random_seed 1238 --max_iter 40000 --random_actions --task_type unstack --depth_channels_history --resume /home/ahundt/src/real_good_robot/logs/2021-02-15-13-26-00_Sim-Vertical-Square-Two-Step-Reward-Masked-Training-Three-Step-History
Commit: 56b439cb74182fd3c8ba3da71da4aa0f506e196b
GPU 1, Tab 1, port 19998, top right v-rep window, v-rep tab 8

TODO(ahundt) halted due to resume bug when changing the iteration count, need to resume. 

) ahundt@spot|~/src/real_good_robot on progress_reversal_fix!
) ± export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount
) 0.65 --tcp_port 19998 --random_seed 1238 --max_iter 40000 --random_actions --task_type unstack --depth_channels_history --resume '/home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History'
) loading snapshot file: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/models/snapshot.reinforcement.pth
) main.py using common sense: True using place common sense: False
) loading snapshot file: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/models/snapshot.reinforcement.pth
) Connected to simulation.
) sim started 1: 0
) sim started 2: 0
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) self.is_testing False self.test_preset_cases False
) CUDA detected. Running with GPU acceleration.
) /home/ahundt/.local/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
)   warnings.warn(warning.format(ret))
) Pre-trained model snapshot loaded from: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/models/snapshot.reinforcement.pth
) Pre-loading data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
) WARNING: Missing /data/variables/nonlocal_vars_32000.json on resume. Default values initialized. Inconsistencies
) 
) Training iteration: 32000
) WARNING: Missing /data/variables/process_action_var_values_32000.json on resume. Default values initialized. May cause log inconsistencies
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) prev_height: 0.0 max_z: 0.05111981340496809 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
) Current count of pixels with stuff: 2562.0 threshold below which the scene is considered empty: 300
) WARNING variable mismatch num_trials + 1: 5019 nonlocal_variables[stack].trial: 4431
) Primitive confidence scores: 5.662470 (push), 5.809417 (grasp), 9.914308 (place)
) Strategy: exploit (exploration probability: 0.500000)
) Action: grasp at (4, 167, 72)
) Executing: grasp at (-0.580000, 0.110000, 0.051032) orientation: 1.570796
) gripper position: 0.03064691461622715
) gripper position: 0.02599448524415493
) gripper position: 0.01037599891424179
) gripper position: 0.00685255229473114
) gripper position: 0.006547838449478149
) gripper position: 0.0047284141182899475
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) gripper position: 0.004923909902572632
) gripper position: 0.00470009446144104
) Grasp successful: True
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) prev_height: 0.0 max_z: 0.05110550500483392 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
) running check_stack_update_goal for grasp action
) check_stack() False, not enough nearby objects for a successful stack! expected at least 4 nearby objects, but only counted: 1
) check_stack() current detected stack height: 1
) unstacking_partial_success() structure_progress: 4 prev_structure_progress: 1 goal_success: True
) check_stack() stack_height: 4 stack matches current goal: True partial_stack_success: True Does the code think a reset is needed: False Does the code think the stack toppled: True
) main.py check_stack() DETECTED PROGRESS REVERSAL, mismatch between the goal height: 1 and current workspace stack height: 4, TOPPLED stack, RESETTING the objects, goals, and action success to FALSE...
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) prev_height: 0.0 max_z: 0.05110550500483392 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) main.py() process_actions: place_success: False
) main.py() process_actions: partial_stack_success: False
) STACK:  trial: 4432 actions/partial: inf  actions/full stack: inf (lower is better)  Grasp Count: 1, grasp success rate: 0.0 place_on_stack_rate: 0 place_attempts: 0  partial_stack_successes: 0  stack_successes: 0 trial_success_rate: inf stack goal: [1 3] current_height: 4
) Time elapsed: 15.983102
) Trainer iteration: 32000 complete
) 
) Training iteration: 32001
) moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
) prev_height: 0.0 max_z: 0.051100958399972155 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
) Current count of pixels with stuff: 2514.0 threshold below which the scene is considered empty: 300
) Change detected: True (value: 4118)
) Trainer.get_label_value(): Current reward: 0.000000 Current reward multiplier: 4.000000 Predicted Future reward: 10.275206 Expected reward: 0.000000 + 0.650000 x 10.275206 = 6.678884
) trial_complete_indices: [1.0000e+00 1.4000e+01 1.5000e+01 ... 3.3336e+04 3.2000e+04 3.2001e+04]
) Max trial success rate: 0.84, at action iteration: 31931. (total of 32000 actions, max excludes first 500 actions)
) Max grasp success rate: 0.9299610894941635, at action iteration: 27093. (total of 28454 actions, max excludes first 500 actions)
) Traceback (most recent call last):
)   File "main.py", line 2345, in <module>
)     one_train_test_run(args)
)   File "main.py", line 2138, in one_train_test_run
)     training_base_directory, best_dict = main(args)
)   File "main.py", line 1551, in main
)     num_trials, best_dict, logger, title, place, prev_best_dict, task_type=task_type)
)   File "main.py", line 1898, in save_plot
)     window=plot_window, num_preset_arrangements=preset_files, task_type=task_type)
)   File "/home/ahundt/src/real_good_robot/plot.py", line 363, in plot_it
)     place_rate, place_lower, place_upper, best, current = get_place_success_rate(heights, actions, window=window, task_type=task_type)
)   File "/home/ahundt/src/real_good_robot/plot.py", line 183, in get_place_success_rate
)     successes = stack_height_increased[start:i+1][success_possible[start:i+1]]
) IndexError: boolean index did not match indexed array along dimension 0; dimension is 501 but corresponding boolean dimension is 500
) -> [1]

Trying a test as-is for now:
TEST: ± export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19998 --random_seed 1238 --max_train_actions 30000 --random_actions --task_type unstack --depth_channels_history --resume '/home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History'

> STACK:  trial: 101 actions/partial: 2.3268482490272375  actions/full stack: 12.72340425531915 (lower is better)  Grasp Count: 291, grasp success rate: 0.8831615120274914 place_on_stack_rate: 1.0 place_attempts: 257  partial_stack_successes: 257  stack_successes: 47 trial_success_rate: 0.46534653465346537 stack goal: [3 1] current_height: 1
> trial_complete_indices: [ 11.  21.  22.  32.  33.  34.  35.  36.  47.  48.  58.  68.  69.  71.
>   72.  74.  84.  87.  97. 108. 109. 120. 121. 131. 141. 151. 152. 153.
>  154. 164. 165. 169. 170. 180. 190. 191. 193. 202. 204. 205. 215. 217.
>  227. 228. 238. 239. 249. 254. 265. 266. 276. 286. 296. 297. 307. 317.
>  328. 329. 338. 343. 354. 364. 365. 366. 381. 391. 401. 411. 418. 427.
>  428. 438. 439. 448. 458. 463. 473. 474. 481. 482. 492. 497. 498. 500.
>  505. 515. 516. 535. 536. 541. 542. 543. 553. 563. 573. 583. 593. 594.
>  595. 596. 597.]
> Max trial success rate: 0.4742268041237113, at action iteration: 594. (total of 596 actions, max excludes first 594 actions)
> Max grasp success rate: 0.8831615120274914, at action iteration: 594. (total of 596 actions, max excludes first 594 actions)
> Max place success rate: 0.9475409836065574, at action iteration: 596. (total of 597 actions, max excludes first 594 actions)
> Max action efficiency: 1.3636363636363635, at action iteration: 596. (total of 597 actions, max excludes first 594 actions)
> saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/trial-success-rate.log.csv
> saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/grasp-success-rate.log.csv
> saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/place-success-rate.log.csv
> saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/action-efficiency.log.csv
> saving plot: 2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History-Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History_success_plot.png
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/data/best_stats.json
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-22-03-02-20_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/best_stats.json
> Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/2021-02-22-00-05-09_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History
> Random Testing results:
>  {'trial_success_rate_best_value': 0.7, 'trial_success_rate_best_index': 778, 'grasp_success_rate_best_value': 0.9217171717171717, 'grasp_success_rate_best_index': 779, 'place_success_rate_best_value': 0.9869791666666666, 'place_success_rate_best_index': 780, 'action_efficiency_best_value': 1.2724935732647815, 'action_efficiency_best_index': 780}
> Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-08-03_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
> Training results:
>  {'action_efficiency_best_index': 33334, 'action_efficiency_best_value': 4.032, 'grasp_success_rate_best_index': 29962, 'grasp_success_rate_best_value': 0.9411764705882353, 'place_success_rate_best_index': 4199, 'place_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 31931, 'trial_success_rate_best_value': 0.84}



DEPTH CHANNEL HISTORY, DENSENET - SIM 2x2 VERTICAL SQUARE - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - PROGRESS REWARD - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-15
----------------------------------------------------------------------------------------
export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19999 --random_seed 1238 --max_iter 40000 --random_actions --task_type vertical_square --depth_channels_history
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-15-13-26-00_Sim-Vertical-Square-Two-Step-Reward-Masked-Training-Three-Step-History
Commit: 4828f395b44bd742f51e6df8a4cb84a51fceb6d6
Crash due to row check sorting bug.
IMPORTANT RESUME CHANGE after iteration 15098 (action number): The definition of successful block on block is now more narrow so 2-1 pyramids aren't accepted as progress step 3.
Resume: ± export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19999 --random_seed 1238 --max_iter 40000 --random_actions --task_type vertical_square --depth_channels_history --resume /home/ahundt/src/real_good_robot/logs/2021-02-15-13-26-00_Sim-Vertical-Square-Two-Step-Reward-Masked-Training-Three-Step-History
Commit: 59f321193e852e9927a81aace7dc47a62b7b4b08
GPU 2, Tab 2, port 19999, bottom left v-rep window, v-rep tab 9

Cancelled because trial success plateaued, trying a new run with extended exploration and trial reward.



DEPTH CHANNEL HISTORY, DENSENET - SIM UNSTACKING - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - PROGRESS REWARD - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-17
----------------------------------------------------------------------------------------

export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_iter 40000 --random_actions --task_type unstacking --depth_channels_history
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-17-12-27-29_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
TESTINNG RUN RESUME (stoped after 30k actions instead of 40k):
export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_train_actions 30000 --random_actions --task_type unstacking --depth_channels_history --resume /home/ahundt/src/real_good_robot/logs/2021-02-17-12-27-29_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History

Commit: c989e94999ed44eba3835c4a1d8bca3a7b5dec18
GPU 0, Tab 0, port 19990, top left v-rep window, v-rep tab 7

> STACK:  trial: 101 actions/partial: 2.1422018348623855  actions/full stack: 12.289473684210526 (lower is better)  Grasp Count: 496, grasp success rate: 0.8830645161290323 place_on_stack_rate: 0.9954337899543378 place_attempts: 438  partial_stack_successes: 436  stack_successes: 76 trial_success_rate: 0.7524752475247525 stack goal: [2 0] current_height: 1
> trial_complete_indices: [  1.  11.  13.  23.  33.  34.  46.  56.  71.  72.  96. 106. 116. 126.
>  136. 146. 155. 160. 170. 182. 187. 188. 205. 215. 220. 230. 242. 243.
>  253. 258. 270. 280. 284. 294. 304. 309. 319. 333. 343. 352. 362. 371.
>  373. 382. 392. 402. 412. 422. 434. 444. 454. 464. 469. 479. 486. 488.
>  497. 502. 503. 513. 524. 534. 552. 557. 567. 577. 587. 596. 606. 611.
>  621. 632. 642. 655. 665. 675. 694. 695. 705. 714. 724. 739. 749. 759.
>  771. 781. 791. 807. 808. 817. 827. 843. 854. 864. 874. 884. 894. 904.
>  914. 924. 933.]
> Max trial success rate: 0.75, at action iteration: 930. (total of 932 actions, max excludes first 930 actions)
> Max grasp success rate: 0.8866396761133604, at action iteration: 931. (total of 932 actions, max excludes first 930 actions)
> Max place success rate: 1.0, at action iteration: 930. (total of 933 actions, max excludes first 930 actions)
> Max action efficiency: 1.070967741935484, at action iteration: 932. (total of 933 actions, max excludes first 930 actions)
> saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/trial-success-rate.log.csv
> saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/grasp-success-rate.log.csv
> saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/place-success-rate.log.csv
> saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/transitions/action-efficiency.log.csv
> saving plot: 2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History-Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History_success_plot.png
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/data/best_stats.json
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History/best_stats.json
> Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-17-12-27-29_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History/2021-02-22-02-58-11_Sim-Unstacking-Two-Step-Reward-Masked-Testing-Three-Step-History
> Random Testing results:
>  {'trial_success_rate_best_value': 0.75, 'trial_success_rate_best_index': 930, 'grasp_success_rate_best_value': 0.8866396761133604, 'grasp_success_rate_best_index': 931, 'place_success_rate_best_value': 1.0,
> 'place_success_rate_best_index': 930, 'action_efficiency_best_value': 1.070967741935484, 'action_efficiency_best_index': 932}
> Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-17-12-27-29_Sim-Unstacking-Two-Step-Reward-Masked-Training-Three-Step-History
> Training results:
>  {'action_efficiency_best_index': 19146, 'action_efficiency_best_value': 1.848, 'grasp_success_rate_best_index': 11020, 'grasp_success_rate_best_value': 0.9411764705882353, 'place_success_rate_best_index': 2496, 'place_success_rate_best_value': 1.0, 'trial_success_rate_best_index': 7810, 'trial_success_rate_best_value': 0.8867924528301887}
> 


X DEPTH CHANNEL HISTORY - SIM STACK - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - FULL FEATURED RUN - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-17
X ----------------------------------------------------------------------------------------
X 
X Ran in to a bad sim bug, so cancelled the run
X 
X export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --check_z_height --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 40000 --random_actions --depth_channels_history
X Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-17-16-21-25_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History
X Commit: 59f321193e852e9927a81aace7dc47a62b7b4b08 release tag:
X Resume: ± export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --check_z_height --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 40000 --random_actions --depth_channels_history --resume /home/ahundt/src/real_good_robot/logs/2021-02-17-16-21-25_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History
X Commit: 6139a134449b0f32ac4799ab93b5f31fc373031d
X GPU 3, Tab 3, port 19998, bottom right v-rep window, v-rep tab 10




DEPTH CHANNEL HISTORY, DENSENET - SIM 2x2 VERTICAL SQUARE - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - GRASP ONLY - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-18
----------------------------------------------------------------------------------------

The rate of exploration has been increased (lower decay rate), no push actions.

export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --place --future_reward_discount 0.65 --tcp_port 19999 --random_seed 1238 --max_iter 40000 --random_actions --task_type vertical_square --depth_channels_history --grasp_only
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-18-16-53-40_Sim-Vertical-Square-SPOT-Trial-Reward-Masked-Training-Three-Step-History
Commit: cbf8d83907348ad3277d84b20839e63fe7394231
resuming due to improvements in bound checks and stuck object checks
Resume: export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --place --future_reward_discount 0.65 --tcp_port 19999 --random_seed 1238 --max_iter 40000 --random_actions --task_type vertical_square --depth_channels_history --grasp_only --resume /home/ahundt/src/real_good_robot/logs/2021-02-18-16-53-40_Sim-Vertical-Square-SPOT-Trial-Reward-Masked-Training-Three-Step-History
Commit: 82b571830ee5ae6da5630d12b9e3c649f075f8d0
GPU 2, Tab 2, port 19999, bottom left v-rep window, v-rep tab 9




DEPTH CHANNEL HISTORY - SIM STACK - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - FULL FEATURED RUN - SORT TRIAL REWARD - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-17
----------------------------------------------------------------------------------------

export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --check_z_height --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 40000 --random_actions --depth_channels_history
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-18-17-27-35_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History
Commit: cbf8d83907348ad3277d84b20839e63fe7394231
resuming due to improvements in bound checks and stuck object checks
± export CUDA_VISIBLE_DEVICES="3" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 8 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --check_z_height --tcp_port 20000 --place --future_reward_discount 0.65 --max_train_actions 40000 --random_actions --depth_channels_history --resume /home/ahundt/src/real_good_robot/logs/2021-02-18-17-27-35_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History
Commit: 82b571830ee5ae6da5630d12b9e3c649f075f8d0
GPU 3, Tab 3, port 19998, bottom right v-rep window, v-rep tab 10

> Trial logging complete: 101 --------------------------------------------------------------
> Running two step backprop()
> Primitive confidence scores: 0.901100 (push), 5.907341 (grasp), 4.742904 (place)
> Action: grasp at (4, 167, 104)
> Training loss: 1.639390
> Executing: grasp at (-0.516000, 0.110000, 0.051020) orientation: 1.570796
> gripper position: 0.0531899556517601
> gripper position: 0.03698894381523132
> gripper position: 0.03255927562713623
> gripper position: 0.03208906948566437
> moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
> Grasp successful: False
> moving to home joint config [0.5888036489486694, -0.04610097035765648, 0.2750997841358185, -0.40353187918663025, -0.8726646304130554]
> prev_height: 0.0 max_z: 0.051129393792964065 goal_success: True needed to reset: False max_workspace_height: -0.02 <<<<<<<<<<<
> running check_stack_update_goal for grasp action
> prev_height: 1.0 max_z: 1.0225878758592812 goal_success: False needed to reset: False max_workspace_height: 0.6 <<<<<<<<<<<
> check_stack() stack_height: 1.0225878758592812 stack matches current goal: False partial_stack_success: False Does the code think a reset is needed: False Does the code think the stack toppled: None
> main.py() process_actions: place_success: False
> main.py() process_actions: partial_stack_success: False
> STACK:  trial: 101 actions/partial: 3.2  actions/full stack: 9.92 (lower is better)  Grasp Count: 540, grasp success rate: 0.837037037037037 place_on_stack_rate: 0.6858407079646017 place_attempts: 452  partial_stack_successes:
> 310  stack_successes: 100 trial_success_rate: 0.9900990099009901 stack goal: None current_height: 1.0225878758592812
> trial_complete_indices: [  9.  17.  23.  27.  33.  39.  46.  64.  73.  79.  83. 107. 124. 130.
>  138. 142. 153. 163. 169. 173. 180. 186. 195. 203. 209. 227. 233. 241.
>  250. 280. 291. 297. 307. 313. 319. 337. 360. 373. 395. 401. 415. 421.
>  427. 433. 439. 453. 459. 465. 474. 481. 487. 496. 502. 508. 514. 524.
>  540. 546. 563. 572. 591. 597. 609. 617. 646. 653. 664. 673. 684. 701.
>  707. 716. 727. 742. 752. 759. 772. 778. 789. 795. 807. 816. 830. 836.
>  848. 866. 870. 876. 887. 901. 908. 914. 931. 938. 943. 950. 959. 968.
>  974. 985. 991.]
> Max trial success rate: 0.99, at action iteration: 988. (total of 990 actions, max excludes first 988 actions)
> Max grasp success rate: 0.8401486988847584, at action iteration: 989. (total of 990 actions, max excludes first 988 actions)
> Max place success rate: 0.8185840707964602, at action iteration: 990. (total of 991 actions, max excludes first 988 actions)
> Max action efficiency: 0.6072874493927125, at action iteration: 990. (total of 991 actions, max excludes first 988 actions)
> saving trial success rate: /home/ahundt/src/real_good_robot/logs/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/trial-success-rate.log.csv
> saving grasp success rate: /home/ahundt/src/real_good_robot/logs/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/grasp-success-rate.log.csv
> saving place success rate: /home/ahundt/src/real_good_robot/logs/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/place-success-rate.log.csv
> saving action efficiency: /home/ahundt/src/real_good_robot/logs/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/transitions/action-efficiency.log.csv
> saving plot: 2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History-Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History_success_plot.png
> /home/ahundt/src/real_good_robot/plot.py:439: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument "optimize" which is no longer supported as of 3.3 and will become an error two minor releases later
>   plt.savefig(save_file + file_format, dpi=300, optimize=True)
> /home/ahundt/src/real_good_robot/plot.py:441: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument "optimize" which is no longer supported as of 3.3 and will become an error two minor releases later
>   plt.savefig(log_dir_fig_file + file_format, dpi=300, optimize=True)
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/data/best_stats.json
> saving best stats to: /home/ahundt/src/real_good_robot/logs/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History/best_stats.json
> Random Testing Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-18-17-27-35_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History/2021-02-26-05-14-20_Sim-Stack-SPOT-Trial-Reward-Masked-Testing-Three-Step-History
> Random Testing results:
>  {'trial_success_rate_best_value': 0.99, 'trial_success_rate_best_index': 988, 'grasp_success_rate_best_value': 0.8401486988847584, 'grasp_success_rate_best_index': 989, 'place_success_rate_best_value': 0.8185840707964602, 'place_success_rate_best_index': 990, 'action_efficiency_best_value': 0.6072874493927125, 'action_efficiency_best_index': 990}
> Training Complete! Dir: /home/ahundt/src/real_good_robot/logs/2021-02-18-17-27-35_Sim-Stack-SPOT-Trial-Reward-Masked-Training-Three-Step-History
> Training results:
>  {'trial_success_rate_best_value': 0.8478260869565217, 'trial_success_rate_best_index': 15414, 'grasp_success_rate_best_value': 0.8759398496240601, 'grasp_success_rate_best_index': 24223, 'place_success_rate_best_value': 0.8355555555555556, 'place_success_rate_best_index': 15767, 'action_efficiency_best_value': 0.6, 'action_efficiency_best_index': 20165}
> 


DEPTH CHANNEL HISTORY, DENSENET - SIM 2x2 VERTICAL SQUARE - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - GRASP ONLY - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-19
----------------------------------------------------------------------------------------

The rate of exploration has been increased (lower decay rate), no push actions.

export CUDA_VISIBLE_DEVICES="2" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --place --future_reward_discount 0.65 --tcp_port 19999 --random_seed 1238 --max_train_actions 40000 --random_actions --task_type vertical_square --depth_channels_history --grasp_only
/home/ahundt/src/real_good_robot/logs/2021-02-19-21-48-03_Sim-Vertical-Square-SPOT-Trial-Reward-Masked-Training-Three-Step-History
Commit: 82b571830ee5ae6da5630d12b9e3c649f075f8d0
GPU 2, Tab 2, port 19999, bottom left v-rep window, v-rep tab 9





X DENSENET - SIM 2x2 VERTICAL SQUARE - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - GRASP ONLY - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-19
X ----------------------------------------------------------------------------------------
X 
X The rate of exploration has been increased (lower decay rate), no push actions.
X 
X export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --place --future_reward_discount 0.65 --tcp_port 19998 --random_seed 1238 --max_train_actions 20000 --random_actions --task_type vertical_square --grasp_only
X Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-22-16-26-15_Sim-Vertical-Square-SPOT-Trial-Reward-Masked-Training
X Commit: 6edeae7f90918f3ded69455ee47a6dce02b4aa02
X GPU 1, Tab 4, port 19998, top right v-rep window, v-rep tab 9
x
X Canceled due to lack of convergence, maybe there is a bug when the grasp_only flag is set.




DENSENET - UNSTACKING - masked - trial reward - common sense - 2020-02-23
----------------------------------------------------------------------------------------
± export CUDA_VISIBLE_DEVICES="0" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --common_sense --place --future_reward_discount 0.65 --tcp_port 19990 --random_seed 1238 --max_train_actions 40000 --random_actions --task_type unstack --trial_reward                                                                                                  
Creating data logging session: /home/ahundt/src/real_good_robot/logs/2021-02-23-02-23-36_Sim-Unstacking-SPOT-Trial-Reward-Masked-TrainingCommit: 61758dd9f669e57245160a3e1aad4017bafb88df
Commit: 61758dd9f669e57245160a3e1aad4017bafb88df
GPU 0, Tab 0, port 19990, top left v-rep window, v-rep tab 7




DENSENET - SIM 2x2 VERTICAL SQUARE - SPOT-Q-MASKED SPOT FRAMEWORK - COMMON SENSE - TRIAL REWARD - FULL FEATURED RUN - REWARD SCHEDULE 0.1, 1, 1 - costar 2020-02-25
----------------------------------------------------------------------------------------

export CUDA_VISIBLE_DEVICES="1" && python3 main.py --is_sim --obj_mesh_dir objects/blocks --num_obj 4 --push_rewards --experience_replay --explore_rate_decay --trial_reward --common_sense --place --future_reward_discount 0.65 --tcp_port 19998 --random_seed 1238 --max_train_actions 20000 --random_actions --task_type vertical_square
Commit: 61758dd9f669e57245160a3e1aad4017bafb88df
GPU 1, Tab 1, port 19998, top right v-rep window, v-rep tab 9